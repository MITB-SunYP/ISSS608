[
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Creating data visualisation beyond default",
    "section": "",
    "text": "This is the take home exercise 1 of ISSS608 Visual Analytics and Applications. In this exercise, we are instructed to analyze a survey data to understand:\n\nthe distribution of Singapore students’ performance in mathematics, reading and science\nthe relationship between these performance with schools, gender and socioeconomic status of the students\n\nDespite the continuous effort from Ministry of Education in Singapore to promote the concept of “Every school a good school”, and all the student should be treated the same regardless of their background. People are still not convinced that the neighborhood schools are comparable with the elite schools.\nTherefore, we’d use the survey data from 2022 Programme for International Student Assessment (PISA) to get some insights into what differentiate the students’ academic performance.\n\n\n\nPISA is a programme from Organization for Economic Co-operation and Development (OECD). It measures 15-year-olds’ ability to use their reading, mathematics and science knowledge and skills to meet real-life challenges, and it’s conducted every three years. The last assessment was conducted in 2022, and the data was made publicly available on PISA’s website.\nIn this exercise, we’d focus on the Student Questionnaire data, and analyze the responses from the participants from Singapore. The full questionnaire could be found with this link.\n\n\n\nAnalyze the responses from Singapore participants, and understand:\n\nthe distribution of Singapore students’ performance in mathematics, reading and science\nthe relationship between these performance with schools, gender and socioeconomic status of the students"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "title": "Creating data visualisation beyond default",
    "section": "",
    "text": "This is the take home exercise 1 of ISSS608 Visual Analytics and Applications. In this exercise, we are instructed to analyze a survey data to understand:\n\nthe distribution of Singapore students’ performance in mathematics, reading and science\nthe relationship between these performance with schools, gender and socioeconomic status of the students\n\nDespite the continuous effort from Ministry of Education in Singapore to promote the concept of “Every school a good school”, and all the student should be treated the same regardless of their background. People are still not convinced that the neighborhood schools are comparable with the elite schools.\nTherefore, we’d use the survey data from 2022 Programme for International Student Assessment (PISA) to get some insights into what differentiate the students’ academic performance.\n\n\n\nPISA is a programme from Organization for Economic Co-operation and Development (OECD). It measures 15-year-olds’ ability to use their reading, mathematics and science knowledge and skills to meet real-life challenges, and it’s conducted every three years. The last assessment was conducted in 2022, and the data was made publicly available on PISA’s website.\nIn this exercise, we’d focus on the Student Questionnaire data, and analyze the responses from the participants from Singapore. The full questionnaire could be found with this link.\n\n\n\nAnalyze the responses from Singapore participants, and understand:\n\nthe distribution of Singapore students’ performance in mathematics, reading and science\nthe relationship between these performance with schools, gender and socioeconomic status of the students"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#understanding-the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#understanding-the-data",
    "title": "Creating data visualisation beyond default",
    "section": "2. Understanding the Data",
    "text": "2. Understanding the Data\n\n2.1 Installing and loading the required libraries\nIn this exercise, we’ll make use the following R packages:\n\ntidyverse: an opinionated collection of R packages designed for data import, data wrangling and data exploration\nhaven: to import data in SPSS, Stata and SAS data format\npatchwork: specially designed for combining separate ggplot2 graphs into a single figure\nggdist: to visualize distribution and uncertainty\nheatmaply: to build interactive heatmap\nggstatsplot: an extension of ggplot2 for creating graphics with detials from statistical tests included in the information-rich plots themselves\n\nLet’s use the code chunk below to load the required R packages.\n\npacman::p_load(tidyverse, haven, patchwork, ggdist, heatmaply, ggstatsplot)\n\n\n\n2.2 Importing the data\nPISA provides the survey data in two formats, SPSS and SAS. In this exercise, we’ve downloaded the data in SAS data format (.sas7bdat).\nThe code chunk below uses read_sas() function of haven package to import PISA data into R environment.\n\nstu_qqq &lt;- read_sas(\"../../Data/cy08msp_stu_qqq.sas7bdat\")\n\nThe dataset contains 1,279 variables, and 613,744 records from respondents all over the world. However, we are only interested in the responses from the participants from Singapore. Therefore, we use the code chunk below to filter the data using CNT (country code) variable.\n\nstu_qqq_sg &lt;- stu_qqq %&gt;% \n  filter(CNT == \"SGP\")\n\nNow, the filtered data only contains 6,606 records from Singapore, and the number of variables remains at 1,279.\nThe code chunk below is used to save the filtered data in rds format which is easier to be used in R environment.\n\nwrite_rds(stu_qqq_sg, \"../../Data/stu_qqq_sg.rds\")\n\nNext, we use the code chunk below to import the rds data for the subsequent analyses.\n\nstu_qqq_sg &lt;- read_rds(\"../../Data/stu_qqq_sg.rds\")\n\n\n\n2.3 Understanding the data\n\n2.3.1 Students’ performance\nIn PISA data, students’ performance was estimated through a set of plausible values. Starting from 2015, PISA provides 10 plausible values for each subject (mathematics, reading and science) instead of 5 in the earlier years. To understand more about plausible values, you may refer to Chapter 6 of PISA Data Analysis Manual.\nBelow lists the 10 plausible variables for each subject:\n\nmathematics: PV1MATH, …, PV10MATH\nreading: PV1READ, …, PV10READ\nscience: PV1SCIE, …, PV10SCIE\n\nThere have been discussions about how to estimate the students’ performance using the plausible values. Although PISA Data Analysis Manual has provided a logic to create estimates, it also mentioned that the imputation error is relatively small with one plausible value if the sample size is large.\nAccording to the table provided in the manual, the imputation error reduces as the sample size grows. The imputation error is 0.23 with a sample size being 6,400.\n\n\n\nsource: PISA Data Analysis Manual\n\n\nSince our Singapore dataset has 6,606 data records, we’ll use the first plausible value of each subject to estimate the students’ proficiency. Hence, the variables that will be used as an estimate of the students’ performance are:\n\nmathematics: PV1MATH\nreading: PV1READ\nscience: PV1SCIE\n\nThe code chunk below provides the summary statistics of the chosen plausible values.\n\nstu_qqq_sg %&gt;%\n  select(PV1MATH, PV1READ, PV1SCIE) %&gt;%\n  summary()\n\n    PV1MATH         PV1READ         PV1SCIE     \n Min.   :218.6   Min.   :135.9   Min.   :187.5  \n 1st Qu.:503.1   1st Qu.:476.9   1st Qu.:495.7  \n Median :582.5   Median :552.9   Median :568.7  \n Mean   :574.2   Mean   :544.4   Mean   :560.8  \n 3rd Qu.:648.2   3rd Qu.:619.6   3rd Qu.:631.1  \n Max.   :943.0   Max.   :859.5   Max.   :873.3  \n\n\n\n\n2.3.2 Students’ school\nPISA data provides a variable called CNTSCHID to indicate the school that the students are from.\nThe code chunk below displays the frequency of each school ID in the variable CNTSCHID.\n\n# Count number of distinct values in School ID variable\nn_distinct(stu_qqq_sg$CNTSCHID)\n\n[1] 164\n\n# Count the number of respondents from each school\ntable(stu_qqq_sg$CNTSCHID)\n\n\n70200001 70200002 70200003 70200004 70200005 70200006 70200007 70200008 \n      55       38       36       56       38       36       38       38 \n70200009 70200010 70200011 70200012 70200013 70200014 70200015 70200016 \n      36       36       56       57       58       36       34       37 \n70200017 70200018 70200019 70200020 70200021 70200022 70200023 70200024 \n      39       52       39       60       37       37       35       36 \n70200025 70200026 70200027 70200028 70200029 70200030 70200031 70200032 \n      38       56       54       22       39       30       56       37 \n70200033 70200034 70200035 70200036 70200037 70200038 70200039 70200040 \n      33       36       56       38       36       40       37       57 \n70200041 70200042 70200043 70200044 70200045 70200046 70200047 70200048 \n       5       37       54       55       58       37       37       36 \n70200049 70200050 70200051 70200052 70200053 70200054 70200055 70200056 \n      56       30       36       55       39       36       35       33 \n70200057 70200058 70200059 70200060 70200061 70200062 70200063 70200064 \n      28       36       39       29       39       57       39       38 \n70200065 70200066 70200067 70200068 70200069 70200070 70200071 70200072 \n      39       58       56       39       33       36       56       34 \n70200073 70200074 70200075 70200076 70200077 70200078 70200079 70200080 \n      38       37       60       37       35       22       31       37 \n70200081 70200082 70200083 70200084 70200085 70200086 70200087 70200088 \n      36       56       36       39       37       37       37       36 \n70200089 70200090 70200091 70200092 70200093 70200094 70200095 70200096 \n      36       40       35       38       38       56       28       36 \n70200097 70200098 70200099 70200100 70200101 70200102 70200103 70200104 \n      35       34       36       34       35       36       36       39 \n70200105 70200106 70200107 70200108 70200109 70200110 70200111 70200112 \n      57       39       35       37       36       57       55       40 \n70200113 70200114 70200115 70200116 70200117 70200118 70200119 70200120 \n      34       51       33       38       37       57       54       37 \n70200121 70200122 70200123 70200124 70200125 70200126 70200127 70200128 \n      37       36       32       32       36       38       37       40 \n70200129 70200130 70200131 70200132 70200133 70200134 70200135 70200136 \n      36       56       39       57       35       38       37       37 \n70200137 70200138 70200139 70200140 70200141 70200142 70200143 70200144 \n      39       15       54       38       58       55       36       37 \n70200145 70200146 70200147 70200148 70200149 70200151 70200152 70200153 \n      55       38       30       31       28       40       38       37 \n70200154 70200155 70200156 70200157 70200158 70200159 70200160 70200161 \n      35       55       37       34       29       59       36       36 \n70200162 70200163 70200164 70200165 \n      40       37       37       39 \n\n\nThere are a total of 164 schools participated in 2022 assessment, and they are represented by a unique school ID. However, I couldn’t find the data dictionary of school ID in PISA’s website. Hence, we’re unable to identify the schools for more in-depth analysis. For example, understand the differences in students’ performance from elite schools and neighborhood schools.\n\n\n2.3.3 Students’ gender\nThe students’ gender is provided in the variable called ST004D01T, where 1 represent females and 2 represent males.\nThe code chunk below displays the frequency of female students and male students.\n\n# frequency\ntable(stu_qqq_sg$ST004D01T)\n\n\n   1    2 \n3248 3358 \n\n# proportion\ntable(stu_qqq_sg$ST004D01T) %&gt;% prop.table() %&gt;% round(2)\n\n\n   1    2 \n0.49 0.51 \n\n\nThere are 3,248 female students which accounts for 49% of the total sample size, and 3,358 male students which accounts for 51% of the total sample size.\n\n\n2.3.4 Students’ socioeconomic status\nThe students’ socioeconomic status in PISA data is represented by an index of economic, social and cultural status (ESCS). It’s a composite score derived from a few aspects of the students’ family background\n\nparents’ highest education\nparents’ highest occupational status\nhome possessions\n\nThe code chunk below shows the summary statistics of the variable ESCS:\n\nstu_qqq_sg %&gt;%\n  select(ESCS) %&gt;%\n  summary()\n\n      ESCS        \n Min.   :-3.5488  \n 1st Qu.:-0.2327  \n Median : 0.4817  \n Mean   : 0.2904  \n 3rd Qu.: 0.9036  \n Max.   : 3.2780  \n NA's   :47"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis",
    "title": "Creating data visualisation beyond default",
    "section": "3. Exploratory Data Analysis",
    "text": "3. Exploratory Data Analysis\nIn this section, we’ll use visual graphics to understand the distribution of the students’ performance in mathematics, reading and science. We are also going to explore if there is any differences among schools, gender and socioeconomic status.\n\n3.1 Overall distribution\nThe code chunk below plots the distribution of the plausible values of mathematics, reading and science.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n# Calculate mean, max and min of the plausible values for mathematics\nmaths_mean &lt;- mean(stu_qqq_sg$PV1MATH)\nmaths_min &lt;- min(stu_qqq_sg$PV1MATH)\nmaths_max &lt;- max(stu_qqq_sg$PV1MATH)\n\n# Plot the histogram of mathematics, and assign it to a variable\nhist_maths &lt;- ggplot(data = stu_qqq_sg,\n             aes(x = PV1MATH)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"chartreuse3\",\n                 fill = \"lightgreen\") +\n  geom_vline(aes(xintercept = maths_mean),\n             color = \"darkgreen\",\n             linetype = \"dashed\") +\n  geom_vline(aes(xintercept = maths_min),\n             color = \"darkgreen\",\n             linetype = \"dashed\") +\n  geom_vline(aes(xintercept = maths_max),\n             color = \"darkgreen\",\n             linetype = \"dashed\") +\n  annotate(\"text\", x = maths_mean, y = 1100,label = paste(\"Mean=\", round(maths_mean, 1)), size = 3, color = \"darkgreen\") +\n  annotate(\"text\", x = maths_min, y = 1000,label = paste(\"Min=\", round(maths_min, 1)), size = 3, color = \"darkgreen\") +\n  annotate(\"text\", x = maths_max - 50, y = 1000,label = paste(\"Max=\", round(maths_max, 1)), size = 3, color = \"darkgreen\") +\n  coord_cartesian(xlim = c(0, 1100),\n                  ylim = c(0, 1100)) +\n  ggtitle(\"Mathematics\") +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8))\n  \n# Calculate mean, max and min of the plausible values for reading\nread_mean &lt;- mean(stu_qqq_sg$PV1READ)\nread_min &lt;- min(stu_qqq_sg$PV1READ)\nread_max &lt;- max(stu_qqq_sg$PV1READ)\n\n# Plot the histogram of reading, and assign it to a variable\nhist_read &lt;- ggplot(data = stu_qqq_sg,\n             aes(x = PV1READ)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"blue\",\n                 fill = \"lightblue\") +\n  geom_vline(aes(xintercept = read_mean),\n             color = \"darkblue\",\n             linetype = \"dashed\") +\n  geom_vline(aes(xintercept = read_min),\n             color = \"darkblue\",\n             linetype = \"dashed\") +\n  geom_vline(aes(xintercept = read_max),\n             color = \"darkblue\",\n             linetype = \"dashed\") +\n  annotate(\"text\", x = read_mean, y = 1100,label = paste(\"Mean=\", round(read_mean, 1)), size = 3, color = \"darkblue\") +\n  annotate(\"text\", x = read_min + 50, y = 1000,label = paste(\"Min=\", round(read_min, 1)), size = 3, color = \"darkblue\") +\n  annotate(\"text\", x = read_max - 50, y = 1000,label = paste(\"Max=\", round(read_max, 1)), size = 3, color = \"darkblue\") +\n  coord_cartesian(xlim = c(0, 1100),\n                  ylim = c(0, 1100)) +\n  ggtitle(\"Reading\") +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8))\n\n# Calculate mean, max and min of the plausible values for science\nscience_mean &lt;- mean(stu_qqq_sg$PV1SCIE)\nscience_min &lt;- min(stu_qqq_sg$PV1SCIE)\nscience_max &lt;- max(stu_qqq_sg$PV1SCIE)\n\n# Plot the histogram of science, and assign it to a variable\nhist_science &lt;- ggplot(data = stu_qqq_sg,\n             aes(x = PV1SCIE)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"red\",\n                 fill = \"pink\") +\n  geom_vline(aes(xintercept = science_mean),\n             color = \"darkred\",\n             linetype = \"dashed\") +\n  geom_vline(aes(xintercept = science_min),\n             color = \"darkred\",\n             linetype = \"dashed\") +\n  geom_vline(aes(xintercept = science_max),\n             color = \"darkred\",\n             linetype = \"dashed\") +\n  annotate(\"text\", x = science_mean, y = 1100,label = paste(\"Mean=\", round(science_mean, 1)), size = 3, color = \"darkred\") +\n  annotate(\"text\", x = science_min + 50, y = 1000,label = paste(\"Min=\", round(science_min, 1)), size = 3, color = \"darkred\") +\n  annotate(\"text\", x = science_max - 50, y = 1000,label = paste(\"Max=\", round(science_max, 1)), size = 3, color = \"darkred\") +\n  coord_cartesian(xlim = c(0, 1100),\n                  ylim = c(0, 1100)) +\n  ggtitle(\"Science\") +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8))\n\nhist_maths + hist_read + hist_science +\n  plot_annotation(\"Distribution of Plausible Values for Each Subject\",\n                  theme = theme(plot.title = element_text(hjust = 0.5)))\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe plausible values of mathematics, reading and science all follow normal distribution. The students in Singapore performed the best in mathematics, with a mean plausible value of 574.2. The mean plausible value for science is 560.8, and reading registered the lowest plausible value with a mean being 544.4.\nThe results are inline with the common perception of Singapore’s education where students are good at mathematics and science subjects. A similar result was also obtained in a 2019 study of Trends in International Mathematics and Science Study (TIMSS), according to a press release from Ministry of Education Singapore.\n\n\n\n\n3.2 Differences between female students and male students\nNext, let’s compare the plausible values between female students and male students.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n# Recode Gender variable to a new string variable\nstu_qqq_sg &lt;- stu_qqq_sg %&gt;% \n  mutate(Gender = case_when(ST004D01T == 1 ~ 'Female',\n                            ST004D01T == 2 ~ 'Male'))\n\n# Raincloud plot of mathematics, and assign it to a variable\nrain_maths &lt;- ggplot(stu_qqq_sg,\n       aes(x = Gender,\n           y = PV1MATH)) +\n  stat_halfeye(position = \"dodge\",\n               width = 0.5,\n               adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA,\n               slab_color = \"chartreuse3\",\n               slab_fill = \"lightgreen\") +\n  geom_boxplot(width = 0.20,\n               outlier.shape = NA,\n               color = \"darkgreen\") +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = 0.5,\n            dotsize = 6,\n            color = \"darkgreen\") +\n  geom_hline(aes(yintercept = maths_mean),\n             color = \"darkgreen\",\n             linetype = \"dashed\") +\n  annotate(\"text\", x = 0, y = maths_mean,label = paste(\"Overall Mean\"), size = 3, color = \"darkgreen\") +\n  coord_flip() +\n  ggtitle(\"Mathematics\") +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8),\n        axis.text = element_text(size = 8),\n        legend.key = element_blank())\n\nrain_read &lt;- ggplot(stu_qqq_sg,\n       aes(x = Gender,\n           y = PV1READ)) +\n  stat_halfeye(position = \"dodge\",\n               width = 0.5,\n               adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA,\n               slab_color = \"blue\",\n               slab_fill = \"lightblue\") +\n  geom_boxplot(width = 0.20,\n               outlier.shape = NA,\n               color = \"darkblue\") +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = 0.5,\n            dotsize = 6,\n            color = \"darkblue\") +\n  geom_hline(aes(yintercept = read_mean),\n             color = \"darkblue\",\n             linetype = \"dashed\") +\n  annotate(\"text\", x = 0, y = read_mean,label = paste(\"Overall Mean\"), size = 3, color = \"darkblue\") +\n  coord_flip() +\n  ggtitle(\"Reading\") +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8),\n        axis.text = element_text(size = 8))\n\nrain_science &lt;- ggplot(stu_qqq_sg,\n       aes(x = Gender,\n           y = PV1SCIE)) +\n  stat_halfeye(position = \"dodge\",\n               width = 0.5,\n               adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA,\n               slab_color = \"red\",\n               slab_fill = \"pink\") +\n  geom_boxplot(width = 0.20,\n               outlier.shape = NA,\n               color = \"darkred\") +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = 0.5,\n            dotsize = 6,\n            color = \"darkred\") +\n  geom_hline(aes(yintercept = science_mean),\n             color = \"darkred\",\n             linetype = \"dashed\") +\n  annotate(\"text\", x = 0, y = science_mean,label = paste(\"Overall Mean\"), size = 3, color = \"darkred\") +\n  coord_flip() +\n  ggtitle(\"Science\") +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8),\n        axis.text = element_text(size = 8))\n\nrain_maths + rain_read + rain_science +\n  plot_annotation(\"Distribution of Plausible Values for Each Subject by Gender\",\n                  theme = theme(plot.title = element_text(hjust = 0.5)))\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nIn general, female students and male students perform similarly in all the three subjects. However, there are still slight difference.\nFemale students did better in reading, while male students did slightly better in mathematics and science. A previous study (Halpern, D.F., Benbow, C.P., etc. 2007) discussed that the differences in the performance between female students and male students in mathematics and science could be indirectly related to the differences in interests and specific brain and cognitive systems.\n\n\n\n\n3.3 Differences among schools\nNext, let’s compare the students performance among different schools. Since there are 164 schools participated in PISA 2022 assessment and there isn’t any information to identify which schools they are, we are unable to group them in any ways but have to compare the mean performance by individual schools.\nIn view of the large number of schools, I’ll use a heat map to see if there is any differences in performance across schools for each subject.\nThe code chunk below prepares the data for plotting the heat map.\n\n# Create a dataframe with the means by each school\nstu_qqq_sg_heat &lt;- stu_qqq_sg %&gt;%\n  group_by(CNTSCHID) %&gt;%\n  summarise_at(vars(PV1MATH, PV1READ, PV1SCIE),\n               funs(mean(.,na.rm = TRUE)))\n\n# Create a new variable for simplified School ID for ease of calculation and display later\nstu_qqq_sg_heat$SCHID_3D &lt;- stu_qqq_sg_heat$CNTSCHID - 70200000\n\n# Change the row names to simplified school ID\nrow.names(stu_qqq_sg_heat) &lt;- stu_qqq_sg_heat$SCHID_3D\n\n# Only keep the variables that are needed for the heat map\nstu_qqq_sg_heat &lt;- stu_qqq_sg_heat %&gt;%\n  dplyr::select(-CNTSCHID, -SCHID_3D)\n\n# Convert the dataframe into a matrix\nstu_qqq_sg_heat_matrix &lt;- data.matrix(stu_qqq_sg_heat)\n\nLet’s now create the heat map.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nheatmaply(stu_qqq_sg_heat_matrix,\n          dendrogram = \"none\",\n          xlab = \"School ID\",\n          ylab = \"Plausible Values\",\n          main = \"Difference in Performance across Schools\",\n          grid_color = \"white\",\n          grid_width = 0.00001,\n          label_names = c(\"School ID: \", \"Subject: \", \"Value\"),\n          fontsize_row = 5,\n          fontsize_col = 5)\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe heat map above shows that there are indeed differences in schools.\nSome schools performed equally badly among all the three subjects, such as School ID 149 (mathematics: 392.8, reading: 328.2, science: 378.7) and School ID 115 (mathematics: 410.5, reading: 390.1, science: 397.7).\nOn the other hand, there are schools performed well in all the three subjects. For example, School ID 154 (mathematics: 689.1, reading: 680.3, science: 678.0) and School ID 62 (mathematics: 690.2, reading: 676.1, science: 666.3).\nNevertheless, most of the schools performed better in mathematics and science than reading in general.\n\n\n\n\n3.4 Differences among socioeconomic status\nNext, let’s take a look at the relationship between the students’ performance and their families’ socioeconomic status.\nThe code chunk below plots the scatter plots between the plausible values and ESCS index.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n# Create scatter plot between mathematics and socioeconomic status\nscatter_maths &lt;- ggscatterstats(data = stu_qqq_sg,\n               x = ESCS,\n               y = PV1MATH,\n               marginal = FALSE,\n               point.args = list(size = 0.5, \n                                 alpha = 0.4, \n                                 color = \"chartreuse3\"),\n               smooth.line.args = list(linewidth = 0.5, \n                                       color = \"gray15\", \n                                       method = \"lm\", \n                                       formula = y ~ x),\n               title = \"Correlation between Mathematics Performance and Socioeconomic Status\") +\n  ggplot2::coord_cartesian(xlim = c(-4, 4),\n                           ylim = c(100, 1000))\n\n# Create scatter plot between reading and socioeconomic status\nscatter_reading &lt;- ggscatterstats(data = stu_qqq_sg,\n               x = ESCS,\n               y = PV1READ,\n               marginal = FALSE,\n               point.args = list(size = 0.5, \n                                 alpha = 0.4, \n                                 color = \"blue\"),\n               smooth.line.args = list(linewidth = 0.5, \n                                       color = \"gray15\", \n                                       method = \"lm\", \n                                       formula = y ~ x),\n               title = \"Correlation between Reading Performance and Socioeconomic Status\") +\n  ggplot2::coord_cartesian(xlim = c(-4, 4),\n                           ylim = c(100, 1000))\n\n# Create scatter plot between science and socioeconomic status\nscatter_science &lt;- ggscatterstats(data = stu_qqq_sg,\n               x = ESCS,\n               y = PV1SCIE,\n               marginal = FALSE,\n               point.args = list(size = 0.5, \n                                 alpha = 0.4, \n                                 color = \"red\"),\n               smooth.line.args = list(linewidth = 0.5, \n                                       color = \"gray15\", \n                                       method = \"lm\", \n                                       formula = y ~ x),\n               title = \"Correlation between Science Performance and Socioeconomic Status\") +\n  ggplot2::coord_cartesian(xlim = c(-4, 4),\n                           ylim = c(100, 1000))\n\nscatter_maths / scatter_reading / scatter_science\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe scatter plot above shows that all the three subjects display marginal positive correlation with the students’ families’ socioeconomic status. The pearson R^2 stays around 0.41 to 0.42 for all the three subjects.\nSince the socioeconomic status is represented by ESCS index which is derived from the parents’ highest education, the parents’ highest occupational status and their home possessions, it suggests the financial stability and the well-being of the families.\nThe students from families with higher ESCS index are more likely to receive high quality of education from their parents which would shape their study behaviors and interests. Their parents can also afford high quality tuition for them, such 1-on-1 home tuition for all the subjects."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary",
    "title": "Creating data visualisation beyond default",
    "section": "4. Summary",
    "text": "4. Summary\n\n4.1 Limitation\nAlthough there are some interesting findings by exploring the differences between the students’ performance in mathematics, reading and science with regards to their gender, school and socioeconomic status, there are some limitations in this take-home exercise.\n\nMost of the insights in the earlier sections are drawn based on the visual graphics. Due to the time constraints, statistical tests are not conducted except the last section on the correlation studies. Therefore, the findings can’t be backed by the statistical evidence. If time allows, I’ll perform statistical tests to validate if those differences discussed are really significant.\nIt’s a pity that PISA didn’t provide a code book to identify the schools. They did that probably to protect the anonymity of the schools. However, this restricts our analysis to understand further about the performance in different types of schools. Although there is a variable to tell if the school is public or private, most of the schools in Singapore are public which makes this variable less useful in Singapore’s context.\n\n\n\n4.2 Conclusion\nThrough the visual checks discussed in this take-home exercise, there are indeed some interesting findings:\n\nThe students in Singapore generally performed better in mathematics and science than reading.\nThe students from different genders excelled in different subjects. Female students outperformed male students in reading, whereas male students generally do better in mathematics and science. This is probably due to their interests and brain systems.\nThere are differences in the academic performance among schools. Some schools are weak in all the three subjects, and some are strong in all the three subjects. Hence, there is still a long way to go before we actually achieve “Every school a good school” in Singapore.\nSocioeconomic status does have some impact on the students’ academic performance. Although the correlation is moderate, but the students from families with higher socioeconomic status generally achieve better results than those from families with lower socioeconomic status. This is probably due to the educational resources and the study environment that the parents could provide to their children.\n\nThis comes to the end of my take-home exercise 1. Hope you enjoyed reading my explorations and findings. See you in the next take-home exercise 🥰"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#reference",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#reference",
    "title": "Creating data visualisation beyond default",
    "section": "5. Reference",
    "text": "5. Reference\nHalpern, D.F., Benbow, C.P., Geary, D.C., Gur, R.C., Hyde, J.S., & Gernsbacher, M.A. (2007). The Science of Sex Differences in Science and Mathematics. Psychological Science in the Public Interest, 8(1), 1-51. https://doi.org/10.1111/j.1529-1006.2007.00032.x"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "In this in-class exercise, two R packages will be used. They are:\n\ntidyverse\nhaven\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse, haven)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "In this in-class exercise, two R packages will be used. They are:\n\ntidyverse\nhaven\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse, haven)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-pisa-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-pisa-data",
    "title": "In-class Exercise 1",
    "section": "Importing PISA data",
    "text": "Importing PISA data\nThe code chunk below uses read_sas() of haven to import PISA data into R environment.\n\nstu_qqq &lt;- read_sas(\"../../Data/cy08msp_stu_qqq.sas7bdat\")\n\nThe dataset contains 1279 variables, and 613744 records from respondents all over the world. However, we are only interested in the responses from the respondents from Singapore. Therefore, we use the code chunk below to filter the data using CNT (country code) variable.\n\nstu_qqq_sg &lt;- stu_qqq %&gt;% \n  filter(CNT == \"SGP\")\n\nNow, the filtered data only contains 6606 records from Singapore, and the number of variables remains at 1279.\nThe code chunk below is used to save the filtered data in rds format.\n\nwrite_rds(stu_qqq_sg, \"../../Data/stu_qqq_sg.rds\")\n\nThe code chunk below is used to import the rds data.\n\nstu_qqq_sg &lt;- read_rds(\"../../Data/stu_qqq_sg.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "In this chapter, we will learn to create more elegant and effective statistical graphics using ggplot2 extensions. By the end of this exercise, we will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package\ncreate professional publication quality figures by using functions provided in ggthemes and hrbrthemes packages\nplot composite figure by combining ggplot2 graphs using pachwork package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#learning-outcome",
    "title": "Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "In this chapter, we will learn to create more elegant and effective statistical graphics using ggplot2 extensions. By the end of this exercise, we will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package\ncreate professional publication quality figures by using functions provided in ggthemes and hrbrthemes packages\nplot composite figure by combining ggplot2 graphs using pachwork package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Beyond ggplot2 Fundamentals",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required libraries\nIn this exercise, other than tidyverse, we’ll learn to use a few new R packages:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels\nggthemes: an R package provides some extra themes, geoms, and scales for ggplot2\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2\npatchwork: an R package for preparing composite figure created using ggplot2\n\nNow, let’s start the exercise by installing these packages\n\npacman::p_load(tidyverse, ggrepel, ggthemes, hrbrthemes, patchwork)\n\n\n\n2.2 Importing the data\nWe’ll continue to use Exam_data throughout this exercise. To recap, this data set contains year end examination grades of a cohort of primary 3 students from a local school. The data file is in csv format.\nLet’s import the data by using read_csv() function of readr package.\n\nexam_data &lt;- read_csv(\"../../Data/Exam_data.csv\")\n\nThe data set consists of 322 rows, and 7 variables.\n\n4 categorical variables: ID, CLASS, GENDER, RACE\n3 numerical variables: ENGLISH, MATHS, SCIENCE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Beyond ggplot2 Fundamentals",
    "section": "3. Beyond ggplot2 Annotation: ggrepel",
    "text": "3. Beyond ggplot2 Annotation: ggrepel\nAnnotation is a common challenge we face while plotting statistical graphs, especial for the data with large number of data points. For example, let’s take a look at the graph below:\n\n\n\n\n\nIn the plot, we want to label the data points with the student ID so it’s easy for data interpretation. However, the labels are clustered together due to the large number of data points in the graph. The student ID becomes non-identifiable in this case.\nWith the help of ggrepel package, we are able to repel the overlapping text labels. What we need to do are:\n\nreplace geom_text() with geom_text_repel()\nreplace geom_label() with geom_label_repel()\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  geom_label_repel(aes(label = ID),\n                   fontface = \"bold\") +\n  coord_cartesian(xlim = c(0, 100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores vs. Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Beyond ggplot2 Fundamentals",
    "section": "4. Beyond ggplot2 Themes",
    "text": "4. Beyond ggplot2 Themes\nIn addition to the data labels, we can also customize the theme of a ggplot. ggplot2 provides 8 built-in themes for us to choose from. The graph below illustrates the 8 built-in themes.\n\n\n\nsource: https://ggplot2.tidyverse.org/reference/ggtheme.html\n\n\nLet’s now plot the histogram of Maths scores with theme_gray().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"gray25\",\n                 fill = \"gray90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n4.1 Working with ggtheme package\nIn addition to the default themes provided in ggplot2, we are also able to choose more themes from ggthemes package.\nThe graph below shows the examples of the themes available in ggthemes package.\n\n\n\n\nsource: https://statisticsglobe.com/ggthemes-package-r\n\n\nLet’s now plot the histogram of Maths scores using theme_economist().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"gray25\",\n                 fill = \"gray90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n4.2 Working with hrbrthemes package\nWe have learned how to change the themes of the plot in the previous section, hrbrthemes package in R allows us to make further customization in the plots.\nMore themes:\n\nScales (that align with various themes):\n\nPalettes/Named Colors:\n\nFonts:\n\nMore information of each function can be found in this link.\nNext let’s plot the histogram of Maths scores using theme_ipsum().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"gray25\",\n                 fill = \"gray90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\nhrbrthemes package also allows us to edit other aspects of the plot to make it more visually appealing. For example,\n\naxis_title_size: an argument to change the font size of the axis title\nbase_size: an argument to font size of the axis label\ngrid: an argument to turn on X/Y gridlines\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"gray25\",\n                 fill = \"gray90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Beyond ggplot2 Fundamentals",
    "section": "5. Beyond Single Graph",
    "text": "5. Beyond Single Graph\nWe have learned how to plot single graph using ggplot2, but we sometimes need to arrange the graphs in a way to tell a more complete story. For example, it’s easier to make comparisons between two graphs if they are arranged side-by-side.\nFortunately, there are a few ggplot2 extensions that can help us acheive this.\nTo do that, let’s first create the individual graphs and assign them to a variable. Then we will use the ggplot2 extensions to compose them in different ways.\nGraph1: let’s plot the histogram of Maths scores, and assign it to a variable called P1.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nP1 &lt;- ggplot(data = exam_data,\n             aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"gray25\",\n                 fill = \"gray90\") +\n  coord_cartesian(xlim = c(0, 100))\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\nGraph2: let’s plot the histogram of English scores, and assign it to a variable called P2.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nP2 &lt;- ggplot(data = exam_data,\n             aes(x = ENGLISH)) +\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"gray25\",\n                 fill = \"gray90\") +\n  coord_cartesian(xlim = c(0, 100))\n  ggtitle(\"Distribution of English scores\")\n\n\n\n\nGraph3: let’s plot a scatterplot for English scores vs. Maths scores, and assign it to a variable called P3.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nP3 &lt;- ggplot(data = exam_data,\n             aes(x = MATHS,\n                 y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) +\n  coord_cartesian(xlim = c(0, 100),\n                  ylim = c(0, 100))\n  ggtitle(\"English scores vs. Maths scores for Primary 3\")\n\n\n\n\n\n5.1 Creating Composite Graphics: pathwork methods\nThere are 3 popular functions enable the users to create composite figures by combining several graphs:\n\ngrid.arrange() from gridExtra package\nplot_grid() from cowplot package\npatchwork: specially designed for combining separate ggplot2 graphs into a single figure\n\nIn this exercise, we’ll focus on patchwork package. The syntax is rather simple to deploy:\n\nUse “+” to arrange the graphs in two columns\nUse “()” to create a subplot group\nUse “/” to arrange the graphs in two rows\nUse “|” to stack two ggplot2 graphs\n\nLet’s now take a look at some examples.\n\n\n5.2 Combining two ggplot2 graphs\nLet’s now arrange the two histograms (P1 & P2) we created earlier in two columns\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nP1 + P2\n\n\n\n\n\n\n5.3 Combining three ggplot2 graphs\nLet’s now arrange the two histograms (P1 & P2) in two rows, and put the scatterplot (P3) to the right of them.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n(P1 / P2) | P3\n\n\n\n\n\n\n5.4 Creating a composite figure with tag\nWe can also tag the graphs using the auto-tagging capability in patchwork.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n((P1 / P2) | P3) +\n  plot_annotation(tag_levels = \"I\")\n\n\n\n\n\n\n5.5 Creating figure with insert\npatchwork also allows us to put the plots next to each other based on the provided layout using inset_element() function.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nP3 + inset_element(P2,\n                   left = 0.02,\n                   bottom = 0.7,\n                   right = 0.5,\n                   top = 1)\n\n\n\n\n\n\n5.6 Creating a composite figure by using patchwork and ggtheme\nLastly, let’s integrate patchwork package with ggthemes package to create the following graph.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (P1 / P2) | P3\npatchwork & theme_economist()\n\n\n\n\nThis comes to the end of this hands-on exercise. I have learned many different methods to customize the plots. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "In this chapter, we will learn the basic principles and essential components of ggplot2. At the same time, we will gain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics.\nAt the end of this chapter, we will be able to apply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcome",
    "title": "A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "In this chapter, we will learn the basic principles and essential components of ggplot2. At the same time, we will gain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics.\nAt the end of this chapter, we will be able to apply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "A Layered Grammar of Graphics: ggplot2 methods",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required libraries\nLet’s first install the required packages for this hands-on exercise.\n\npacman::p_load(tidyverse)\n\n\n\n2.2 Importing the data\nThe data that would be used for this hands-on exercise is called “Exam_data”, which contains the year end examination grades of a cohort of primary 3 students from a local school.\nLet’s import the data using read_csv() function.\n\nexam_data &lt;- read_csv(\"../../Data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe data contains 7 variables. 4 of them are categorical variables, and 3 of them are numerical variables.\n\nCategorical variables: ID, CLASS, GENDER, RACE\nNumerical variables: MATHS, ENGLISH, SCIENCE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "title": "A Layered Grammar of Graphics: ggplot2 methods",
    "section": "3 Introducing ggplot",
    "text": "3 Introducing ggplot\n\n3.1 Compare G Graphics against ggplot\nFirst, let us compare how R Graphics, the core graphical functions of Base R and ggplot plot a simple histogram.\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\nAlthough the syntax for G Graphics is simpler, ggplot2 is more popular because it’s more flexible in customizing the plots. Therefore, it’s more visually appealing to the audience."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "title": "A Layered Grammar of Graphics: ggplot2 methods",
    "section": "4 Grammar of Graphics",
    "text": "4 Grammar of Graphics\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. There are a total of seven grammers in ggplot2:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5 Essential Grammatical Elements in ggplot2: data",
    "text": "5 Essential Grammatical Elements in ggplot2: data\nLet us call the ggplot() function using the code chunk below.\n\nggplot(data=exam_data)\n\n\n\n\nggplot() has initialized a ggplot object, but it’s expected to have a blank canvas because we only defined the dataset to be used for the plot."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "A Layered Grammar of Graphics: ggplot2 methods",
    "section": "6 Essential Grammatical Elements in ggplot2: Aesthetic mappings",
    "text": "6 Essential Grammatical Elements in ggplot2: Aesthetic mappings\nLet’s now add x axis in the plot by using the code chunk below.\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\nAs we can see in the plot, an x axis labelled as “MATHS” has been added."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "title": "A Layered Grammar of Graphics: ggplot2 methods",
    "section": "7 Essential Grammatical Elements in ggplot2: geom",
    "text": "7 Essential Grammatical Elements in ggplot2: geom\nNext, we can define the type of plot by using “geom” object. There are a few types of “geom” objects that’s available:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\nA plot must have at least one geom; there is no upper limit. We can add a geom to a plot using the + operator.\n\n7.1 Geometric Objects: geom_bar\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n7.2 Geometric Objects: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\nThe y axis doesn’t provide any useful information, so let’s remove it. We’ll also change the binwidth to 2.5\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n7.3 Geometric Objects: geom_histogram()\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n7.4 Modifying a geometric object by changing geom()\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n7.5 Modifying a geometric object by changing aes()\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n7.6 Geometric Objects: geom-density()\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n7.7 Geometric Objects: geom_boxplot\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n7.8 Geometric Objects: geom_violin\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n7.9 Geometric Objects: geom_point()\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n7.10 geom objects can be combined\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "A Layered Grammar of Graphics: ggplot2 methods",
    "section": "8 Essential Grammatical Elements in ggplot2: stat",
    "text": "8 Essential Grammatical Elements in ggplot2: stat\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n8.1 Working with stat()\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n8.2 Working with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\n\n\n8.3 Working with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)          \n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n8.4 Adding a best fit curve on a scatterplot\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\n\n\n\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "A Layered Grammar of Graphics: ggplot2 methods",
    "section": "9 Essential Grammatical Elements in ggplot2: Facets",
    "text": "9 Essential Grammatical Elements in ggplot2: Facets\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n9.1 Working with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n9.2 facet_grid() function\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "A Layered Grammar of Graphics: ggplot2 methods",
    "section": "10 Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "10 Essential Grammatical Elements in ggplot2: Coordinates\nThe Coordinates functions map the position of objects onto the plane of the plot.\n\n10.1 Working with Coordinate\nBy default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n10.2 Changing the y- and x-axis range\nThe scatterplot on the right is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "A Layered Grammar of Graphics: ggplot2 methods",
    "section": "11 Essential Grammatical Elements in ggplot2: themes",
    "text": "11 Essential Grammatical Elements in ggplot2: themes\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\n\n11.1 Working with theme\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html",
    "title": "Programming Interactive Data Visualization with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn to create interactive data visualization by using functions provided by ggiraph and plotlyr packages in R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#learning-outcome",
    "title": "Programming Interactive Data Visualization with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn to create interactive data visualization by using functions provided by ggiraph and plotlyr packages in R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#getting-started",
    "title": "Programming Interactive Data Visualization with R",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required libraries\nFirstly, let’s install and load the required packages:\n\ntidyverse: an opinionated collection of R packages designed for data import, data wrangling and data exploration\npatchwork: an R package for preparing composite figure created using ggplot2\nggiraph: to make ggplot graphs interactive\nplotly: to plot interative statistical graphs\nDT: provides an R interface to JavaScript library DataTables that create interactive tables on html page\n\n\npacman::p_load(tidyverse, patchwork, ggiraph, plotly, DT)\n\n\n\n2.2 Importing the data\nSimilar to the previous two hands-on exercise, we’ll still use Exam_data for this exercise. The data file contains year end examination grades of a cohort of primary 3 students from a local school, and it’s in csv format.\nLet’s start by importing the data.\n\nexam_data &lt;- read_csv(\"../../Data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Programming Interactive Data Visualization with R",
    "section": "3. Interactive Data Visualisation - ggiraph methods",
    "text": "3. Interactive Data Visualisation - ggiraph methods\nIn this section, we’ll learn how to make the ggplot graphs interactive. It makes it easier to digest the graphs, especially when we want to use the graphs for story telling.\nThe can be achieved by using ggplot geometries, which has three arguments:\n\nTooltip: a column of data-sets that contains tooltips to be displayed when we mouse over the elements\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked\nData_id: a column of data-sets that contain an id to be associated with elements\n\n\n3.1 Tooltip effect with tooltip aesthetic\n\n3.1.1 Create a graph with ONE tooltip\nIt takes two steps to create an interactive ggplot graph:\n\nStep 1: create a graph using standard ggplot syntax. The only difference is to use the interactive version of ggplot2 geom. According to ggiraph website, almost all ggplot2 elements can be made interactive. Some of examples are:\n\ngeom_point_interactive(…)\ngeom_bar_interactive(…)\ngeom_col_interactive(…)\ngeom_tile_interactive(…)\n\n\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID), # to display ID when mouse over the dots in the graph\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\n\nStep 2: generate an svg object to be displayed on an html page\n\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6 * 0.618\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nWhen we put our mouse over an dot on the graph above, the respective student ID will be displayed.\n\n\n\n\n3.1.2 Create a graph with MULTIPLE tooltip\nThe example above only displayed one information, student ID, when we mouse over the dots. We can actually display more information by specifying a list object as shown in the code chunk below.\n\n# Step 1: create a column in exam_data to store the information that we want to display, by concatenating the information from a few columns\n\nexam_data$tooltip &lt;- c(paste0(\n  \"Name = \", exam_data$ID,\n  \"\\n Class = \", exam_data$CLASS))\n\n# Step 2: create a standard ggplot2 object\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), # supply the newly created tooltip column to tooltip argument\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\n# Step 3: create an SVG object using girafe() function\n\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nWhen we put our mouse over an dot on the graph above, the respective student ID and their classes will now be displayed.\n\n\n\n\n3.1.3 Customising Tooltip style\nWe can also customize tooltip using opts_tooltip() function by adding css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)  \n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nWhen we put our mouse over an dot on the graph above, the tooltip is now displayed with a white background now.\n\n\n\n\n3.1.4 Displaying statistics on tooltip\nWe can also customize the tooltip to display statistical summary information. For example, we can create a function to compute 90% confident interval of the mean, and display it in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = 0.01){\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores: \", mean, \" +/- \", sem)\n}\n\ngg_point &lt;- ggplot(data = exam_data,\n                   aes(x = RACE)) +\n  stat_summary(aes(y = MATHS,\n                   tooltip = after_stat(\n                     tooltip(y, ymax))), \n               fun.data = \"mean_se\",\n               geom = GeomInteractiveCol,\n               fill = \"lightblue\") +\n  stat_summary(aes(y = MATHS),\n               fun.data = mean_se,\n               geom = \"errorbar\",\n               width = 0.2,\n               size = 0.2)\n\ngirafe(\n  ggobj = gg_point,\n  width_svg = 8,\n  height_svg = 8 * 0.618\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nWhen we put our mouse over a bar, the desired statistics is displayed. In our example above, the mean maths score is displayed with 90% confidence interval.\n\n\n\n\n\n3.2 Hover effect with data_id aesthetic\nIn addition to display the tooltip when we mouse over a data point, we can also highlight a subset of the data points using another feature called data_id.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS,\n        tooltip = ID), # to highlight the data points from the same class when mouse over            \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6 * 0.618                      \n)                                        \n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nWhen we mouse over a data point, the other data points which are from the same class are also highlighted.\nNote that the default highlight color is orange, but it can be changed using hover_css = “fill:orange;”\n\n\n\n3.2.1 Styling hover effect\nLet’s now try change the highlighting effect in the graph.\n\np &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6 * 0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nWhen we mouse over a data point, only the data points from the same class are highlighted in black and the rest of the points are dimmed.\n\n\n\n\n3.2.2 Combining tooltip and hover effect\nNow, let’s combine tooltip and data_id features to make the graph more informative.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, # to display class information when hover over\n        data_id = CLASS), # to highlight the data from the same class when hover over             \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6 * 0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity: 0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nWhen we mouse over a data point, only the data points from the same class are highlighted in black and the rest of the points are dimmed. At the same time, the class information is displayed as well.\n\n\n\n\n\n3.3 Click effect with onclick\nggiraph also provides a feature to allow us to redirect the user to a webpage when they click on the graph.\nThe code chunk below shows an example.\n\n# Create a column in exam_data to store the website address\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6 * 0.618)                                        \n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nWhen we click on a data point, a webpage is opened automatically to look for the school with the respective school ID.\n\n\n\n\n3.4 Coordinated Multiple Views with ggiraph\nWe can also plot coordinated multiple views to highlight the related information regarding the same data point.\n\n# Step 1: create the first interactive graph\np1 &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim = c(0, 100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n# Step 2: create the second interactive graph\np2 &lt;- ggplot(data = exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim = c(0, 100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n# Combine the two graphs using patchwork package\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nWhen we hover over a data point in any of the two graphs, the related data point is also highlighted in the other graph."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation---plotly-methods",
    "title": "Programming Interactive Data Visualization with R",
    "section": "4. Interactive Data Visualisation - plotly methods!",
    "text": "4. Interactive Data Visualisation - plotly methods!\nThere is another package available in R to create interactive graphs, that is plotly package. It can be done in two ways:\n\nusing plot_ly()\nusing ggplotly()\n\n\n4.1 Creating an interactive scatter plot: plot_ly() method\nThe code chunk below shows an example.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n4.2 Working with visual variable: plot_ly() method\nWe can add another dimension to the plot by coloring the data points base on a categorical variable, for example, RACE.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nThe color did not just provide another piece of information, it can also act as filters to the plot. The data points are filtered when we click on the categories in the legend.\n\n\n\n\n4.3 Creating an interactive scatter plot: ggplotly() method\nLet’s now create an interactive scatter plot.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data = exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size = 1) +\n  coord_cartesian(xlim = c(0, 100),\n                  ylim = c(0, 100))\n\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nThe coordinates are now displayed when we hover over a data point.\n\n\n\n\n4.4 Coordinated Multiple Views with plotly\nSimilar to ggiraph package, we can also create coordinated multiple views using plotly package.\n\nhighlight_key() of plotly package is used as shared data\ntwo scatterplots will be created by using ggplot2 functions\nsubplot() of plotly package is used to place them next to each other side-by-side\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\n\np1 &lt;- ggplot(data = d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size = 1) +\n  coord_cartesian(xlim = c(0, 100),\n                  ylim = c(0, 100))\n\np2 &lt;- ggplot(data = d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size = 1) +\n  coord_cartesian(xlim = c(0, 100),\n                  ylim = c(0, 100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Programming Interactive Data Visualization with R",
    "section": "5. Interactive Data Visualisation - crosstalk methods!",
    "text": "5. Interactive Data Visualisation - crosstalk methods!\nLastly, let’s make more interactions in R.\n\n5.1 Interactive Data Table: DT package\nThe data tables can also be interactive with the help of a DataTables wrapper from the JavaScript library.\n\nDT::datatable(exam_data, class = \"compact\")\n\n\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nUnlike the traditional way of displaying the data tables, there is a search box above the table to allow us type the texts and the table will be filtered accordingly.\n\n\n\n\n5.2 Linked brushing: crosstalk method\nWe can even combine the plot and the data table, and make them interlinked.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data) \n\np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size = 1) +\n  coord_cartesian(xlim = c(0, 100),\n                  ylim = c(0, 100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5) \n\n\n\n\nThis comes to the end of this hands-on exercise. I have learned many different methods to create interactive plots in R. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html",
    "title": "Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn to\n\ncreate animated data visualization by using gganimate and plotly R packages\nreshape data using tidyr package\nprocess, wrangle and transform data using dplyr package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#learning-outcome",
    "title": "Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn to\n\ncreate animated data visualization by using gganimate and plotly R packages\nreshape data using tidyr package\nprocess, wrangle and transform data using dplyr package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#getting-started",
    "title": "Programming Animated Statistical Graphics with R",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required libraries\nFirstly, let’s install and load the required packages:\n\ntidyverse: an opinionated collection of R packages designed for data import, data wrangling and data exploration\nplotly: to plot interative statistical graphs\ngganimate: to plot animated visualization\ngifski: to convert images to GIF animations\ngapminder: An excerpt of the data available at Gapminder.org. We’ll use its country_colors scheme.\nreadxl: to read data from excel files\n\n\npacman::p_load(tidyverse, plotly, gganimate, gifski, gapminder, readxl)\n\n\n\n2.2 Importing the data\nIn this hands-on exercise, we’ll use the Data worksheet from GlobalPopulation Excel workbook\nLet’s start by importing the data.\n\ncol &lt;- c(\"Country\", \"Continent\")\n\nglobalPop &lt;- read_xls(\"../../Data/GlobalPopulation.xls\",\n                      sheet = \"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;% # to convert all character data into factor\n  mutate(Year = as.integer(Year)) # to convert Year column into integer\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. Therefore, we will replace the function with mutate_at() function. Alternatively, across() function can also be used to achieve the same output.\n\n\nExample code using mutate_at() function.\n\ncol &lt;- c(\"Country\", \"Continent\")\n\nglobalPop &lt;- read_xls(\"../../Data/GlobalPopulation.xls\",\n                      sheet = \"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nExample code using across() function.\n\ncol &lt;- c(\"Country\", \"Continent\")\n\nglobalPop &lt;- read_xls(\"../../Data/GlobalPopulation.xls\",\n                      sheet = \"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#animated-data-visualisation-gganimate-methods",
    "title": "Programming Animated Statistical Graphics with R",
    "section": "3. Animated Data Visualisation: gganimate methods",
    "text": "3. Animated Data Visualisation: gganimate methods\nNow, let’s use gganimate methods to create some animated visualizations. The visualizations are generated using the following functions:\n\ntransition_(): defines how the data should be spread out and how it relates to itself across time.\nview_(): defines how the positional scales should change along the animation.\nshadow_(): defines how data from other points in time should be presented in the given point in time.\nenter_()/exit_(): defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes(): defines how different aesthetics should be eased during transitions.\n\n\n3.1 Building a static population bubble plot\nLet’s first create a static bubble plot using ggplot2 method.\n\nggplot(globalPop, aes(x = Old, \n                      y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n3.2 Building the animated bubble plot\nNext, let’s make the bubbles move by using the two functions below:\n\ntransition_time(): to create transition through distinct states in time (i.e. Year).\nease_aes(): to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, \n                      y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b.html#animated-data-visualisation-plotly",
    "title": "Programming Animated Statistical Graphics with R",
    "section": "4. Animated Data Visualisation: plotly",
    "text": "4. Animated Data Visualisation: plotly\nNow, let’s make the animated visualization interactive by using ggplotly() method.\n\n4.1 Building an animated bubble plot: ggplotly() method\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\nAlthough we have turned off legend using show.legend = FALSE argument, it stills shows in the plot. To overcome this problem, theme(legend.position=‘none’) should be used as shown in the plot and code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position = 'none')\n\nggplotly(gg)\n\n\n\n\n\n\n4.2 Building an animated bubble plot: plot_ly() method\nAnother way to make animated bubble plot is to use plot_ly() function.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\n\nbp\n\n\n\n\nThis comes to the end of this hands-on exercise. I have learned many different methods to create animated visualizations in R. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Data Vis Makeover",
    "section": "",
    "text": "This is the take home exercise 2 of ISSS608 Visual Analytics and Applications. In this exercise, we are instructed to refer to the take home exercise 1 of one of our fellow classmates, and discuss his / her visualizations in terms of clarity and aesthetics.\n\n\n\nThe discussions in this take home exercise is based on this work."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#setting-the-scene",
    "title": "Data Vis Makeover",
    "section": "",
    "text": "This is the take home exercise 2 of ISSS608 Visual Analytics and Applications. In this exercise, we are instructed to refer to the take home exercise 1 of one of our fellow classmates, and discuss his / her visualizations in terms of clarity and aesthetics.\n\n\n\nThe discussions in this take home exercise is based on this work."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-preparation",
    "title": "Data Vis Makeover",
    "section": "2. Data Preparation",
    "text": "2. Data Preparation\n\n2.1 Installing and loading the required libraries\nThe chunk below is used to install and load the R packages that were used by the original author.\n\npacman::p_load(tidyverse, haven, dplyr, plotly, ggrepel, patchwork, \n               ggthemes, hrbrthemes, jpeg, ggiraph, ggdist)\n\n\n\n2.2 Import the data\nThe data used for our take home exercise 1 is a survey data from PISA, which measures 15-year-olds’ ability to use their reading, mathematics and science knowledge and skills to meet real-life challenges. If you’d like to find out more about the dataset, you may refer to my take home exercise 1.\nLet’s first import the dataset.\n\nstu_qqq_sg &lt;- read_rds(\"../../Data/stu_qqq_sg.rds\")\n\nNext, we’ll follow the code provided by the original author to make a subset of the data, and compute the average plausible values for mathematics, reading and science.\n\n# Create a new dataset PV by extracting relevant variables from stu_qqq_sg\nPV &lt;- stu_qqq_sg %&gt;%\n  mutate(\n    Math_Score = rowMeans(select(., starts_with(\"PV1MATH\"), starts_with(\"PV2MATH\"), starts_with(\"PV3MATH\"), starts_with(\"PV4MATH\"), starts_with(\"PV5MATH\"), starts_with(\"PV6MATH\"), starts_with(\"PV7MATH\"), starts_with(\"PV8MATH\"), starts_with(\"PV9MATH\"), starts_with(\"PV10MATH\")), na.rm = TRUE),\n    Reading_Score = rowMeans(select(., starts_with(\"PV1READ\"), starts_with(\"PV2READ\"), starts_with(\"PV3READ\"), starts_with(\"PV4READ\"), starts_with(\"PV5READ\"), starts_with(\"PV6READ\"), starts_with(\"PV7READ\"), starts_with(\"PV8READ\"), starts_with(\"PV9READ\"), starts_with(\"PV10READ\")), na.rm = TRUE),\n    Science_Score = rowMeans(select(., starts_with(\"PV1SCIE\"), starts_with(\"PV2SCIE\"), starts_with(\"PV3SCIE\"), starts_with(\"PV4SCIE\"), starts_with(\"PV5SCIE\"), starts_with(\"PV6SCIE\"), starts_with(\"PV7SCIE\"), starts_with(\"PV8SCIE\"), starts_with(\"PV9SCIE\"), starts_with(\"PV10SCIE\")), na.rm = TRUE),\n    Total_Score = Math_Score + Reading_Score + Science_Score,\n    Gender = ifelse(ST004D01T == 1,  \"Female\", \"Male\"),\n    Own_Room = ifelse(ST250Q01JA == 1, \"Yes\" , \"No\"),\n    mi_num = ST251Q06JA\n  ) %&gt;%\n  select(CNTSCHID, CNTSTUID, Math_Score, Reading_Score, Science_Score, Total_Score, Gender, Own_Room, mi_num)\n\nAs described by the original author, we use the code chunk below to convert school ID and student ID to string variables. We’ll also clear the missing values in the new dataset.\n\n# Convert numerical variables to string variables\nPV$CNTSCHID &lt;- as.character(PV$CNTSCHID)\nPV$CNTSTUID &lt;- as.character(PV$CNTSTUID)\n\n# Clear missing values\nPV &lt;- na.omit(PV)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-discussion-and-remake",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-discussion-and-remake",
    "title": "Data Vis Makeover",
    "section": "3. Visualization Discussion and Remake",
    "text": "3. Visualization Discussion and Remake\n\n3.1 Distribution of Student Performance\nOriginal plot\n\nWhat’s good about this plot?\nThe original author chose the right type of graph to view the distribution of the subjects, which is the histograms. It is easy for us to see if the data exhibits any abnormal patterns, for example, skewness or multi-model distribution.\nWhat can be improved?\n\nIt isn’t very obvious to identify the plots for each subject as they are all in the same color. My suggestion is to use different colors to represent different subjects.\nThe scales could be aligned across all the charts so to avoid mis-interpretation when comparing the mean scores among the three subjects.\nDensity curves could be added to show the smoothness of the curves.\nThe plots could be better arranged to show the relationship among individual subjects and the total scores.\n\nA remake of the plot\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nplot1 &lt;- ggplot(data = PV, aes(x = Math_Score, y = after_stat(density))) +\n  geom_histogram(bins = 10, boundary = 100, color = \"chartreuse3\", fill = \"lightgreen\") +\n  geom_density(lwd = 0.8, colour = \"darkgreen\") +\n  scale_y_continuous(labels = scales::percent) +\n  coord_cartesian(xlim = c(100, 900)) +\n  ggtitle(\"Distribution of Maths Scores\")+\n  theme_minimal() +\n  theme(text = element_text(size = 8),\n        plot.title = element_text(hjust = 0.5))\n  \nplot2 &lt;- ggplot(data = PV, aes(x = Reading_Score, y = after_stat(density))) +\n  geom_histogram(bins = 10, boundary = 100, color = \"blue\", fill = \"lightblue\") +\n  geom_density(lwd = 0.8, colour = \"darkblue\") +\n  scale_y_continuous(labels = scales::percent) +\n  coord_cartesian(xlim = c(100, 900)) +\n  ggtitle(\"Distribution of Reading Scores\")+\n  theme_minimal() +\n  theme(text = element_text(size = 8),\n        plot.title = element_text(hjust = 0.5))\n\nplot3 &lt;- ggplot(data = PV, aes(x = Science_Score, y = after_stat(density))) +\n  geom_histogram(bins = 10, boundary = 100, color = \"red\", fill = \"pink\") +\n  geom_density(lwd = 0.8, colour = \"darkred\") +\n  scale_y_continuous(labels = scales::percent) +\n  coord_cartesian(xlim = c(100, 900)) +\n  ggtitle(\"Distribution of Science Scores\")+\n  theme_minimal() +\n  theme(text = element_text(size = 8),\n        plot.title = element_text(hjust = 0.5))\n\nplot4 &lt;- ggplot(data = PV, aes(x = Total_Score, y = after_stat(density))) +\n  geom_histogram(bins = 10, boundary = 100, color = \"gray25\", fill = \"gray95\") +\n  geom_density(lwd = 0.8, colour = \"gray10\") +\n  scale_y_continuous(labels = scales::percent) +\n  coord_cartesian(xlim = c(200, 2600)) +\n  ggtitle(\"Distribution of Total Scores\")+\n  theme_minimal() +\n  theme(text = element_text(size = 8),\n        plot.title = element_text(hjust = 0.5))\n\n(plot1 / plot2 / plot3) | plot4\n\n\n\n\n\n\n3.2 Student Performance by Gender\nOriginal plot\n\nWhat’s good about this plot?\nWhile comparing the distribution between genders, the author used different colors so it’s easy to differentiate the distributions for female students and male students.\nWhat can be improved?\n\nAlthough there are supposed to be two colors to represent female students and male students, it seems to be three categories when we first look at the graph because a third color is created at the area where the two distributions overlap. I’d suggest to use density curves without filling color.\nSince we need to use different colors to represent different categories, we can’t use colors to differentiate the subjects as we did in the previous section. An alternative way is to display an icon in the plots so the audience can easily identify the subjects.\n\nA remake of the plot\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n# Maths: Plot the density curves by gender with maths image\nimg_maths &lt;- readJPEG(\"images/Maths.jpg\", native = TRUE)\n\nplot1 &lt;- ggplot(data = PV, aes(x = Math_Score, color = Gender)) +\n  geom_density(alpha = 0.7, position = \"identity\", stat = \"density\",lwd = 0.8) +  \n  labs(title = \"Math Scores by Gender\") +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(labels = scales::percent) +\n  coord_cartesian(xlim = c(100, 900)) +\n  theme_minimal() +\n  theme(text = element_text(size = 8), plot.title = element_text(hjust = 0.5))\n\nplot1_img &lt;- plot1 +\n  inset_element(p = img_maths,\n                 left = 0.1,\n                 bottom = 0.7,\n                 right = 0.3,\n                 top = 0.9)\n\n# Reading: Plot the density curves by gender with reading image\nimg_read &lt;- readJPEG(\"images/Reading.jpg\", native = TRUE)\n\nplot2 &lt;- ggplot(data = PV, aes(x = Reading_Score, color = Gender)) +\n  geom_density(alpha = 0.7, position = \"identity\", stat = \"Density\", lwd = 0.8) +\n  labs(title = \"Reading Scores by Gender\") +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(labels = scales::percent)+\n  coord_cartesian(xlim = c(100, 900)) +\n  theme_minimal() +\n  theme(text = element_text(size = 8),\n        plot.title = element_text(hjust = 0.5))\n\nplot2_img &lt;- plot2 +\n  inset_element(p = img_read,\n                 left = 0.1,\n                 bottom = 0.7,\n                 right = 0.3,\n                 top = 0.9)\n\n# English: Plot the density curves by gender with English image\nimg_science &lt;- readJPEG(\"images/Science.jpg\", native = TRUE)\n\nplot3 &lt;- ggplot(data = PV, aes(x = Science_Score, color = Gender)) +\n  geom_density(alpha = 0.7, position = \"identity\", stat = \"Density\", lwd = 0.8) +\n  labs(title = \"Science Scores by Gender\") +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(labels = scales::percent)+\n  coord_cartesian(xlim = c(100, 900)) +\n  theme_minimal() +\n  theme(text = element_text(size = 8),\n        plot.title = element_text(hjust = 0.5))\n\nplot3_img &lt;- plot3 +\n  inset_element(p = img_science,\n                 left = 0.1,\n                 bottom = 0.7,\n                 right = 0.3,\n                 top = 0.9)\n\n# Total: Plot the density curves by gender with total image\nimg_total &lt;- readJPEG(\"images/Total.jpg\", native = TRUE)\n\nplot4 &lt;- ggplot(data = PV, aes(x = Total_Score, color = Gender)) +\n  geom_density(alpha = 0.7, position = \"identity\", stat = \"density\", lwd = 0.8) +\n  labs(title = \"Total Scores by Gender\") + \n  scale_y_continuous(labels = scales::percent)+\n  coord_cartesian(xlim = c(200, 2600)) +\n  theme_minimal() +\n  theme(text = element_text(size = 8),\n        plot.title = element_text(hjust = 0.5))\n\nplot4_img &lt;- plot4 +\n  inset_element(p = img_total,\n                 left = 0.1,\n                 bottom = 0.7,\n                 right = 0.3,\n                 top = 0.9)\n\nplot1_img + plot2_img + plot3_img + plot4_img\n\n\n\n\n\n\n3.3 Student Performance by School\nOriginal plot\n\nWhat’s good about this plot?\nBoxplot is one of the ways to view the distribution of the performance across schools. The author also showed school IDs of the outliers to help identify if any schools performed well or bad for each of the subjects.\nWhat can be improved?\n\nStatic boxplot has its limitations when the audience try to draw a story across different subjects, for example, if there is any schools that performed consistently good or bad across all the subjects.\nI’d also suggest to use different color to represent different subjects for easy identification.\nTherefore, a coordinated interactive graph would allow the audience to easily see the performance of a selected school across subjects. In my makeover below, I’ll choose dot plot to represent the data as it’s easier for me to see the schools’ performance across subjects.\n\nA remake of the plot\nWe’ll first follow the author’s code chunk to calculate the average scores for each school for each subject.\n\nSchool_Avg_Scores &lt;- PV %&gt;%\n  group_by(CNTSCHID) %&gt;%\n  summarize(\n    Avg_Math_Score = mean(Math_Score, na.rm = TRUE),\n    Avg_Reading_Score = mean(Reading_Score, na.rm = TRUE),\n    Avg_Science_Score = mean(Science_Score, na.rm = TRUE),\n    Avg_Score = mean(Total_Score/3, na.rm = TRUE)\n  )\n\nSchool_Avg_Scores_subjects &lt;- School_Avg_Scores %&gt;%\n  select(CNTSCHID, starts_with(\"Avg_Math\"), starts_with(\"Avg_Reading\"), starts_with(\"Avg_Science\"),starts_with(\"Avg_Score\"))\n\nSchool_Avg_Scores_long &lt;- School_Avg_Scores_subjects %&gt;%\n  pivot_longer(cols = -CNTSCHID, names_to = \"Subject\", values_to = \"Score\")\n\nNow let’s remake the plot.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n# Create dot plot for Maths\nSchool_Avg_Scores$tooltip_maths &lt;- c(paste0(\n  \"School ID = \", School_Avg_Scores$CNTSCHID,\n  \"\\n Ave Maths Score = \", School_Avg_Scores$Avg_Math_Score\n))\n\nplot1 &lt;- ggplot(data = School_Avg_Scores,\n            aes(x = Avg_Math_Score)) +\n  geom_dotplot_interactive(\n    aes(data_id = CNTSCHID, tooltip = tooltip_maths), # to display ID when mouse over the dots in the graph\n    stackgroups = TRUE,\n    binwidth = 1,\n    dotsize = 8,\n    color = \"darkgreen\",\n    fill = \"chartreuse3\",\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\n# Create dot plot for Reading\nSchool_Avg_Scores$tooltip_read &lt;- c(paste0(\n  \"School ID = \", School_Avg_Scores$CNTSCHID,\n  \"\\n Ave Maths Score = \", School_Avg_Scores$Avg_Reading_Score\n))\n\nplot2 &lt;- ggplot(data = School_Avg_Scores,\n            aes(x = Avg_Reading_Score)) +\n  geom_dotplot_interactive(\n    aes(data_id = CNTSCHID, tooltip = tooltip_read), # to display ID when mouse over the dots in the graph\n    stackgroups = TRUE,\n    binwidth = 1,\n    dotsize = 8,\n    color = \"blue\",\n    fill = \"lightblue\",\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\n# Create dot plot for Science\nSchool_Avg_Scores$tooltip_science &lt;- c(paste0(\n  \"School ID = \", School_Avg_Scores$CNTSCHID,\n  \"\\n Ave Maths Score = \", School_Avg_Scores$Avg_Science_Score\n))\n\nplot3 &lt;- ggplot(data = School_Avg_Scores,\n            aes(x = Avg_Science_Score)) +\n  geom_dotplot_interactive(\n    aes(data_id = CNTSCHID, tooltip = tooltip_science), # to display ID when mouse over the dots in the graph\n    stackgroups = TRUE,\n    binwidth = 1,\n    dotsize = 8,\n    color = \"red\",\n    fill = \"pink\",\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\n# Combine the three plots\ngirafe(\n  code = print(plot1 + plot2 + plot3),\n  width_svg = 6,\n  height_svg = 3,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )\n)\n\n\n\n\n\n\n3.4 Student Performance by Musical Instruments\nOriginal plot\n\nWhat’s good about this plot?\nThe intention was good where the author explored the correlation between the performance of the three subjects and the number of musical instruments owned. However, I don’t think scatter plot is suitable for this purpose.\nWhat can be improved?\n\nThe number of musical instruments owned are in integer form, where as the scores of the subjects are in continuous form. This leads to the data points are displayed on the vertical line which is hard for any interpretation.\nAlthough the author displayed a best fit line in the graphs to show the trend, it’s hard to correlate the trend line to the dots.\nI’d suggest to use one of the following visualizations to represent the data: boxplot, violin plot, or rain cloud plots.\n\nA remake of the plot\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nPV$mi_num_s &lt;- as.character(PV$mi_num)\n\nplot1 &lt;- ggplot(PV,\n       aes(x = mi_num_s,\n           y = Math_Score)) +\n  xlab(\"Number of Musical Instruments\") +\n  stat_halfeye(position = \"dodge\",\n               width = 0.5,\n               adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA,\n               slab_color = \"chartreuse3\",\n               slab_fill = \"lightgreen\") +\n  geom_boxplot(width = 0.20,\n               outlier.shape = NA,\n               color = \"darkgreen\") +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)+\n  coord_flip() +\n  ggtitle(\"Math Score by Musical instruments\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8),\n        axis.text = element_text(size = 8))\n\nplot2 &lt;- ggplot(PV,\n       aes(x = mi_num_s,\n           y = Reading_Score)) +\n  xlab(\"Number of Musical Instruments\") +\n  stat_halfeye(position = \"dodge\",\n               width = 0.5,\n               adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA,\n               slab_color = \"blue\",\n               slab_fill = \"lightblue\") +\n  geom_boxplot(width = 0.20,\n               outlier.shape = NA,\n               color = \"darkblue\") +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)+\n  coord_flip() +\n  ggtitle(\"Reading Score by Musical instruments\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8),\n        axis.text = element_text(size = 8))\n\nplot3 &lt;- ggplot(PV,\n       aes(x = mi_num_s,\n           y = Science_Score)) +\n  xlab(\"Number of Musical Instruments\") +\n  stat_halfeye(position = \"dodge\",\n               width = 0.5,\n               adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA,\n               slab_color = \"red\",\n               slab_fill = \"pink\") +\n  geom_boxplot(width = 0.20,\n               outlier.shape = NA,\n               color = \"darkred\") +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)+\n  coord_flip() +\n  ggtitle(\"Science Score by Musical instruments\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8),\n        axis.text = element_text(size = 8))\n\nplot4 &lt;- ggplot(PV,\n       aes(x = mi_num_s,\n           y = Total_Score)) +\n  xlab(\"Number of Musical Instruments\") +\n  stat_halfeye(position = \"dodge\",\n               width = 0.5,\n               adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA,\n               slab_color = \"gray25\",\n               slab_fill = \"gray95\") +\n  geom_boxplot(width = 0.20,\n               outlier.shape = NA,\n               color = \"gray10\") +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)+\n  coord_flip() +\n  ggtitle(\"Total Score by Musical instruments\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8),\n        axis.text = element_text(size = 8))\n\nplot1 + plot2 + plot3 + plot4\n\n\n\n\n\n\n3.5 Student Performance by Own Room\nOriginal plot\n\nWhat’s good about this plot?\nBox plot is a good choice to compare if there is any differences in the scores between the students who have their own room and those who share room.\nWhat can be improved?\n\nEverything is in the same color makes it difficult for the audience to differentiate the plots between subjects and categories.\nThe axis values are not synchronized to make cross reference among the subjects.\nSince this is a visualization course, maybe we can try something else.\n\nA remake of the plot\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nplot1 &lt;- ggplot(PV,\n       aes(x = Own_Room,\n           y = Math_Score)) +\n  geom_violin(color = \"chartreuse3\",\n              fill = \"lightgreen\") +\n  geom_boxplot(width = 0.1, \n               color = \"darkgreen\",\n               alpha = 0.2, \n               outlier.shape = NA) +\n  theme_minimal() +\n  ggtitle(\"Math Score by Private Space\") +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8),\n        axis.text = element_text(size = 8))\n  \nplot2 &lt;- ggplot(PV,\n       aes(x = Own_Room,\n           y = Reading_Score)) +\n  geom_violin(color = \"blue\",\n              fill = \"lightblue\") +\n  geom_boxplot(width = 0.1, \n               color = \"darkblue\",\n               alpha = 0.2, \n               outlier.shape = NA) +\n  theme_minimal() +\n  ggtitle(\"Reading Score by Private Space\") +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8),\n        axis.text = element_text(size = 8))\n\nplot3 &lt;- ggplot(PV,\n       aes(x = Own_Room,\n           y = Science_Score)) +\n  geom_violin(color = \"red\",\n              fill = \"pink\") +\n  geom_boxplot(width = 0.1, \n               color = \"darkred\",\n               alpha = 0.2, \n               outlier.shape = NA) +\n  theme_minimal() +\n  ggtitle(\"Science Score by Private Space\") +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8),\n        axis.text = element_text(size = 8))\n\nplot4 &lt;- ggplot(PV,\n       aes(x = Own_Room,\n           y = Total_Score)) +\n  geom_violin(color = \"gray25\",\n              fill = \"gray95\") +\n  geom_boxplot(width = 0.1, \n               color = \"gray10\",\n               alpha = 0.2, \n               outlier.shape = NA) +\n  theme_minimal() +\n  ggtitle(\"Total Score by Private Space\") +\n  theme(plot.title = element_text(size = 8, hjust = 0.5),\n        axis.title = element_text(size = 8),\n        axis.text = element_text(size = 8))\n\nplot1 + plot2 + plot3 + plot4\n\n\n\n\nThis comes to the end of my take-home exercise 2. Hope you enjoyed reading my work. See you in the next take-home exercise 🥰"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "title": "Visualizing Distribution",
    "section": "",
    "text": "In this hands-on exercise, we will learn another two new ways to visualize the distribution of the data by using ridgeline plot and raincloud plot."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "title": "Visualizing Distribution",
    "section": "",
    "text": "In this hands-on exercise, we will learn another two new ways to visualize the distribution of the data by using ridgeline plot and raincloud plot."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started",
    "title": "Visualizing Distribution",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required libraries\nFirstly, let’s install and load the required packages:\n\ntidyverse: an opinionated collection of R packages designed for data import, data wrangling and data exploration\nggridges: a ggplot2 extension specially designed for plotting ridgeline plots\nggdist: to visualise distribution and uncertainty\n\n\npacman::p_load(tidyverse, ggridges, ggdist, ggthemes, colorspace)\n\n\n\n2.2 Importing the data\nSimilar to the previous hands-on exercises, we’ll still use Exam_data for this exercise. The data file contains year end examination grades of a cohort of primary 3 students from a local school, and it’s in csv format.\nLet’s start by importing the data.\n\nexam &lt;- read_csv(\"../../Data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-distribution-with-ridgeline-plot",
    "title": "Visualizing Distribution",
    "section": "3. Visualising Distribution with Ridgeline Plot",
    "text": "3. Visualising Distribution with Ridgeline Plot\nRidgeline plot, also known as Joyplot, is a type of visualization toview the distribution of a numerical value for several groups. The distribution can be arranged on the same horizontal scale for easy comparison.\nBelow is an example to compare the distribution of English scores across classes through ridgeline plot.\n\n\n3.1 Plotting ridgeline graph: ggridges method\nIn this section, we’ll learn to plot ridgeline plot using ggridges package. We’ll mainly use two geoms:\n\ngeom_ridgeline(): takes height values to draw ridgelines\ngeom_density_ridges(): estimates data densities and then draw using ridgelines\n\nLet’s look at an example below:\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n3.2 Varying fill colors along the x axis\nThe R package also enables us to change the color in the ridgeline plots, by using geom_ridgeline_gradient() or geom_density_ridges_gradient().\nLet’s look at an example below:\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = after_stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n3.3 Mapping the probabilities directly onto colour\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5 - stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n3.4 Ridgeline plots with quantile lines\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#the-code-3",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#the-code-3",
    "title": "Visualizing Distribution",
    "section": "The code",
    "text": "The code\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#the-code-4",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#the-code-4",
    "title": "Visualizing Distribution",
    "section": "The code",
    "text": "The code\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-distribution-with-raincloud-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-distribution-with-raincloud-plot",
    "title": "Visualizing Distribution",
    "section": "4. Visualising Distribution with Raincloud Plot",
    "text": "4. Visualising Distribution with Raincloud Plot\nIn this section, we will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n4.1 Plotting a Half Eye graph\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n4.2 Adding the boxplot with geom_boxplot()\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n4.3 Adding the Dot Plots with stat_dots()\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = 0.5,\n            dotsize = 2)\n\n\n\n\n\n\n4.4 Finishing touch\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = 0.20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = 0.5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()\n\n\n\n\nThis comes to the end of this hands-on exercise. I have learned to create ridgeline plots and raincloud plots in R. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#the-code-5",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#the-code-5",
    "title": "Visualizing Distribution",
    "section": "The code",
    "text": "The code\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "title": "Visual Statistical Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will learn the following:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "title": "Visual Statistical Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will learn the following:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#getting-started",
    "title": "Visual Statistical Analysis",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required libraries\nFirstly, let’s install and load the required packages:\n\ntidyverse: an opinionated collection of R packages designed for data import, data wrangling and data exploration\nggstatsplot: an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves\n\n\npacman::p_load(tidyverse, ggstatsplot)\n\n\n\n2.2 Importing the data\nSimilar to the previous hands-on exercises, we’ll still use Exam_data for this exercise. The data file contains year end examination grades of a cohort of primary 3 students from a local school, and it’s in csv format.\nLet’s start by importing the data.\n\nexam &lt;- read_csv(\"../../Data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#one-sample-test-gghistostats-method",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#one-sample-test-gghistostats-method",
    "title": "Visual Statistical Analysis",
    "section": "3. One-sample test: gghistostats() method",
    "text": "3. One-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n3.1 Unpacking the Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10.\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n3.2 How to interpret Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#two-sample-mean-test-ggbetweenstats",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#two-sample-mean-test-ggbetweenstats",
    "title": "Visual Statistical Analysis",
    "section": "4. Two-sample mean test: ggbetweenstats()",
    "text": "4. Two-sample mean test: ggbetweenstats()\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\n\n\nTry it out\n\n\n\nThe Mann-Whitney statistic is displayed on the plot to tell if the two distributions are significantly different. Since the p-value is larger than 0.05, we can conclude that the maths scores between female students and male students are not significantly different at 5% significance level."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#oneway-anova-test-ggbetweenstats-method",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#oneway-anova-test-ggbetweenstats-method",
    "title": "Visual Statistical Analysis",
    "section": "5. Oneway ANOVA Test: ggbetweenstats() method",
    "text": "5. Oneway ANOVA Test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\nA few values that we can choose for pairwise.display: - “ns” → only non-significant - “s” → only significant - “all” → everything\n\n\n\n\n\n\nTry it out\n\n\n\nWelch test is performed to check if the English scores varies among different races significantly. Since the p-value is less than 0.05, we can conclude that the English scores distributed significantly different among races at 5% significance level."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#significant-test-of-correlation-ggscatterstats",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#significant-test-of-correlation-ggscatterstats",
    "title": "Visual Statistical Analysis",
    "section": "6. Significant Test of Correlation: ggscatterstats()",
    "text": "6. Significant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nThe plot above shows that there is a strong positive correlation between English scores and Maths scores, as the Pearson correlation coefficient is 0.83."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#significant-test-of-association-depedence-ggbarstats-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#significant-test-of-association-depedence-ggbarstats-methods",
    "title": "Visual Statistical Analysis",
    "section": "7. Significant Test of Association (Depedence) : ggbarstats() methods",
    "text": "7. Significant Test of Association (Depedence) : ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association.\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-models",
    "title": "Visual Statistical Analysis",
    "section": "8. Visualising Models",
    "text": "8. Visualising Models\nIn this section, we will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n8.1 Installing and loading the required libraries\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(readxl, performance, parameters, see, ggstatsplot, tidyverse)\n\n\n\n8.2 Importing Excel file: readxl methods\nLet’s first import the data using read_xls() function from readxl package. In this exercise, we’ll use the data worksheet of ToyotaCorolla.xls workbook.\n\ncar_resale &lt;- read_xls(\"../../Data/ToyotaCorolla.xls\", \"data\")\n\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nThe data is imported as a tibble table in R. There are 1,436 rows, and 38 columns in the dataset.\n\n5 categorical variables\n33 numerical variables\n\n\n\n\n\n8.3 Multiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n            data = car_resale)\n\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\n\n\n\nTry it out\n\n\n\nThe results above provides the intercept of the model and the coefficients of the factors.\n\nintercept: -2.637e+06\nAge_08_04: -1.409e+01\nMfg_Year: 1.315e+03\nKM: -2.323e-02\nWeight: 1.903e+01\nGuarantee_Period: 2.770e+01\n\n\n\n\n\n8.4 Model Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package is used to check if multicolinearity exists in the model.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nThe results above shows that Age_08_04 and Mfg_Year is highly correlated as the VIF value is larger than 10.\nIn this case, we shall remove one of them and retrain the model.\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n8.5 Model Diagnostic: checking normality assumption\nLet’s remove the manufacturing year and retrain the model.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + Weight + Guarantee_Period, \n             data = car_resale)\n\nIn the code chunk, check_normality() of performance package is used to check if the residuals of the model follows the normal distribution.\n\ncheck_n &lt;- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nThe plot above shows that some residuals are not along the 0 reference line, which indicates that the residuals are not normally distributed.\n\n\n\n\n8.6 Model Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package is used to check for homogeneity of variance.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nAs the reference line shows an upward trend, it indicates that heterogeneity exists in the residuals.\n\n\n\n\n8.7 Model Diagnostic: Complete check\nWe can also perform the complete checkings by using check_model() function.\n\ncheck_model(model1)\n\n\n\n\n\n\n8.8 Visualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nIt’s clear from the plot above that Age_08_04 and KM have negative impact on the price, whereas weight and guarantee period have positive impact on the price.\nA factor with a negative impact indicates that the higher the value is, the lower the price is. On the other hand, a factor with a postive impact indicates that the higher the values is, the higher the price is.\n\n\n\n\n8.9 Visualising Regression Parameters: ggcoefstats() methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")\n\n\n\n\nThis comes to the end of this hands-on exercise. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html",
    "title": "Hands-on_Ex04d Funnel Plots for Fair Comparisons",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, we will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#overview",
    "title": "Hands-on_Ex04d Funnel Plots for Fair Comparisons",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, we will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#getting-started",
    "title": "Hands-on_Ex04d Funnel Plots for Fair Comparisons",
    "section": "2. Getting started",
    "text": "2. Getting started\n\n2.1 Installing and Launching R Packages\nIn this exercise, four R packages will be used. They are:\n\nreadr: for importing csv into R.\nFunnelPlotR: for creating funnel plot.\nggplot2: for creating funnel plot manually.\nknitr: for building static html table.\nplotly: for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\n\n2.3 Importing Data\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as of 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"../../Data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\n\n\n\n\n\n\nTry it out\n\n\n\nThere are 267 rows, and 7 columns in the dataset. The columns contains:\n\n3 character variables\n4 numerical variables"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#funnelplotr-methods",
    "title": "Hands-on_Ex04d Funnel Plots for Fair Comparisons",
    "section": "3. FunnelPlotR methods",
    "text": "3. FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n3.1 FunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If City is chosen, there are only six data points.\nBy default, data_type argument is “SR” which stands for standardized ratio.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n3.2 FunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",     #&lt;&lt; PR stands for proportions\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n3.3 FunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04d.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on_Ex04d Funnel Plots for Fair Comparisons",
    "section": "4. Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "4. Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, we will gain hands-on experience on building funnel plots step-by-step by using ggplot2.\n\n4.1 Computing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate * (1 - rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n4.2 Calculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n4.3 Plotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n4.4 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly\n\n\n\n\n\nThis comes to the end of this hands-on exercise. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "title": "Hands-on_Ex04c Visualising Uncertainty",
    "section": "",
    "text": "In this chapter, we will gain hands-on experience on creating statistical graphics for visualising uncertainty of a point statistic or a prediction from a statistical model. By the end of this chapter we will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced visualizations by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#learning-outcome",
    "title": "Hands-on_Ex04c Visualising Uncertainty",
    "section": "",
    "text": "In this chapter, we will gain hands-on experience on creating statistical graphics for visualising uncertainty of a point statistic or a prediction from a statistical model. By the end of this chapter we will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced visualizations by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#getting-started",
    "title": "Hands-on_Ex04c Visualising Uncertainty",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse: a family of R packages for data science process,\nplotly: for creating interactive plot,\ngganimate: for creating animation plot,\nDT: for displaying interactive html table,\ncrosstalk: for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist: for visualising distribution and uncertainty.\n\nIn order to use gganimate package, we need to obtain the installer from a github repository using devtools.\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk, DT, ggdist, ggridges, colorspace, gganimate, tidyverse)\n\n\n\n2.2 Data import\nThe dataset used in this exercise is Exam_data.csv.\n\nexam &lt;- read_csv(\"../../Data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on_Ex04c Visualising Uncertainty",
    "section": "3. Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "3. Visualizing the uncertainty of point estimates: ggplot2 methods\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\nIn this section, you will learn how to plot error bars of maths scores by race using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n = n(),\n    mean = mean(MATHS),\n    sd = sd(MATHS)\n    ) %&gt;%\n  mutate(se = sd / sqrt(n - 1))\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nThe codeThe table\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\n3.1 Plotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n3.2 Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\nTry it out\n\n\n\nThe graph above shows that Chinese students have the highest mean Maths score and Malay students have the lowest mean Maths score. However, the 95% confidence interval for Indian students is the widest among all the races.\n\n\n\n\n3.3 Visualizing the uncertainty of point estimates with interactive error bars\nIn this section, we will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4, 8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x = reorder(RACE, -mean),\n                     ymin = mean - 2.58 * se, \n                     ymax = mean + 2.58 * se), \n                     width = 0.2, \n                     colour = \"black\", \n                     alpha = 0.9, \n                     size = 0.5) +\n                   geom_point(aes(\n                     x = RACE, \n                     y = mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean - 2.58 * se), digits = 2), \",\",\n                                  round((mean + 2.58 * se), digits = 2), \"]\")),\n                     stat = \"identity\", \n                     color = \"red\", \n                     size = 1.5, \n                     alpha = 1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust = 1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class = \"compact\", \n                     width = \"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX = T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns = c('mean', 'sd', 'se'),\n                     digits = 2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on_Ex04c Visualising Uncertainty",
    "section": "4. Visualising Uncertainty: ggdist package",
    "text": "4. Visualising Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n4.1 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median (The default statistic is mean, but we can also change the value of this argument to display median)\n.interval = qi\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n4.2 Visualizing the uncertainty of point estimates: ggdist methods\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n4.3 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on_Ex04c Visualising Uncertainty",
    "section": "5. Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "5. Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\nStep 1: Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nAs we have done this step at the beginning of this exercise, we’ll skip this step here.\nStep 2: Launch the application in R\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "title": "Hands-on_Ex04c Visualising Uncertainty",
    "section": "6. Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "6. Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)\n\n\n\n\nThis comes to the end of this hands-on exercise. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "title": "Creating Ternary Plot with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#learning-outcome",
    "title": "Creating Ternary Plot with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#getting-started",
    "title": "Creating Ternary Plot with R",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required libraries\nFirstly, let’s install and load the required packages:\n\ntidyverse: an opinionated collection of R packages designed for data import, data wrangling and data exploration\nggtern: a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nplotly: an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\n\npacman::p_load(tidyverse, ggtern, plotly)\n\n\n\n2.2 Importing the data\nWe’ll use Singapore population data downloaded from Singapore Department of Statistics for this hands-on exercise. It contains data of Singapore population by age group and planning area from June 2000 to 2018. The data file is in csv format.\nLet’s start by importing the data.\n\npop_data  &lt;- read_csv(\"../../Data/respopagsex2000to2018_tidy.csv\")\n\nThe data contains 108,126 rows and 5 columns:\n\n3 character variables: planning area, subzone, age group\n2 numerical variables: year, population\n\n\n\n2.3 Preparing the data\nNext, let’s create 3 new variables: young, active and old using age groups.\n\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)\n\nIn the new dataset, age groups has been transformed into columns. The 3 new columns are created in the last 3 colnumns."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#plotting-ternary-diagram-with-r",
    "title": "Creating Ternary Plot with R",
    "section": "3. Plotting Ternary Diagram with R",
    "text": "3. Plotting Ternary Diagram with R\n\n3.1 Plotting a static ternary diagram\nLet’s create a simple static ternary diagram to visualize the 3 new columns we just created.\n\nggtern(data = agpop_mutated,\n       aes(x = YOUNG, \n           y = ACTIVE, \n           z = OLD)) +\n  geom_point()\n\n\n\n\nLet’s make the plot easier to interpret.\n\nggtern(data = agpop_mutated,\n       aes(x = YOUNG, \n           y = ACTIVE, \n           z = OLD)) +\n  geom_point() +\n  labs(title = \"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n3.2 Plotting an interative ternary diagram\nNow, let’s plot an interactive ternary plot\n\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )\n\n\n\n\n\nThis comes to the end of this hands-on exercise. I have learned to create ternary plots in R. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html",
    "title": "Visual Correlation Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to plot data visualisation for visualising correlation matrix with R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#learning-outcome",
    "title": "Visual Correlation Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to plot data visualisation for visualising correlation matrix with R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#getting-started",
    "title": "Visual Correlation Analysis",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required libraries\nFirstly, let’s install and load the required packages:\n\ntidyverse: an opinionated collection of R packages designed for data import, data wrangling and data exploration\ncorrplot: provides a visual exploratory tool on correlation matrix that supports automatic variable reordering to help detect hidden patterns among variables.\nggstatsplot: a ggplot2 extension for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\n\npacman::p_load(tidyverse, corrplot, ggstatsplot, plotly)\n\n\n\n2.2 Importing the data\nWe’ll use wine quality data from UCI Machine Learning Repository for this hands-on exercise. The orginal data is stored in two datasets, one is for red vinho wine samples and the other one is for white vinho wine samples. We’ll combine these two datasets, and the data is saved in a csv file.\nLet’s start by importing the data.\n\nwine  &lt;- read_csv(\"../../Data/wine_quality.csv\")\n\nThe data contains 6,497 rows and 13 columns:\n\n1 character variables:\n\ntype\n\n12 numerical variables:\n\nfixed acidity\nvolatile acidity\ncitric acid\nresidual sugar\nchlorides\nfree sulfur dioxide\ntotal sulfur dioxide\ndensity\npH\nsulphates\nalcohol\nquality"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#building-correlation-matrix-pairs-method",
    "title": "Visual Correlation Analysis",
    "section": "3. Building Correlation Matrix: pairs() method",
    "text": "3. Building Correlation Matrix: pairs() method\nIn this section, we will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\n\n3.1 Building a basic correlation matrix\nLet’s first create a basic correlation matrix using the first 11 columns which describe the characteristics of the wine.\n\npairs(wine[ , 1:11])\n\n\n\n\nIt is a 11 x 11 correlation matrix, and it’s symmetrical along the diagonal. This correlation matrix is helpful when we check for multi-collinearity among the variables.\nNext, we can create a correlation matrix to see which variable has strong correlation with wine quality.\n\npairs(wine[ , 2:12])\n\n\n\n\n\n\n3.2 Drawing the lower corner\nWe noticed that the upper half of the correlation matrix provides the same information as the lower half of the matrix. Therefore, we can set an argument to show only the lower half of the matrix.\n\npairs(wine[ , 2:12], upper.panel = NULL)\n\n\n\n\nof course, we can also choose to show the upper half of the matrix.\n\npairs(wine[ , 2:12], lower.panel = NULL)\n\n\n\n\n\n\n3.3 Including with correlation coefficients\nWe can also show the correlation coefficients in the matrix to allows us to make better judgement.\n\npanel.cor &lt;- function(x, y, digits = 2, prefix = \"\", cex.cor, ...) {\n  usr &lt;- par(\"usr\")\n  on.exit(par(usr))\n  par(usr = c(0, 1, 0, 1))\n  r &lt;- abs(cor(x, y, use = \"complete.obs\"))\n  txt &lt;- format(c(r, 0.123456789), digits = digits)[1]\n  txt &lt;- paste(prefix, txt, sep = \"\")\n  if(missing(cex.cor)) \n    cex.cor &lt;- 0.8 / strwidth(txt)\n  text(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[ , 2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#visualising-correlation-matrix-ggcormat",
    "title": "Visual Correlation Analysis",
    "section": "4. Visualising Correlation Matrix: ggcormat()",
    "text": "4. Visualising Correlation Matrix: ggcormat()\nWhile the scatter plots is straight forward to visualize the correlation between two variables when sample size is small, it becomes challenging as the sample size grows.\nIn this section, we’ll use ggcormat() function from ggstatsplot to overcome this limitation.\n\n4.1 The basic plot\nOne of the ways is to use color scale to represent the strength of correlation.\n\nggstatsplot::ggcorrmat(\n  data = wine,\n  cor.vars = 1:11\n)\n\n\n\n\nThe plot tells us which pairs have insignificant correlation by marking a cross in the respective boxes.\nWe can add a title and subtitle in the plot to make it more informative.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\nIn addition, we can also customize the font size of the title and x / y axis labels.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\",\n  ggplot.component = list(\n    theme(text = element_text(size = 5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))\n)\n\n\n\n\n\n\n4.2 Building multiple plots\nggstatsplot package also allows us to plot multiple correlation matrix. For example, we can plot one matrix for red wine and one for white wine.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Visual Correlation Analysis",
    "section": "5. Visualising Correlation Matrix using corrplot Package",
    "text": "5. Visualising Correlation Matrix using corrplot Package\nIn the next section, we’ll learn how to visualize correlation matrix using corrplot plackage.\n\n5.1 Getting started with corrplot\nUnlike the previous methods, we need to compute the correlation matrix of wine data frame before creating the plot.\n\nwine.cor &lt;- cor(wine[ , 1:11])\n\nNow, we can make the plot using the correlation matrix just created.\n\ncorrplot(wine.cor)\n\n\n\n\nBoth the intensity of the colors and the size of the circles indicate the strength of the pairwise correlation.\n\n\n5.2 Working with visual geometrics\nThe package provides a few options for us to customize our plots by changing the method argument.\nFor example, we can set method = ellipse to show the direction of the correlation.\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n5.3 Working with layout\nWe can choose to show either upper or lower half of the matrix to remove redundancy.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type = \"lower\")\n\n\n\n\nWe can remove the diagonal by setting diag = FALSE.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n5.4 Working with mixed layout\nSimilar to the previous method, we can show correlation coefficient in the correlation matrix plot.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n5.5 Combining corrgram with the significant test\nLet’s now add significance test results in the correlation matrix plot.\n\nwine.sig = cor.mtest(wine.cor, conf.level = 0.95)\n\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = 0.05)\n\n\n\n\n\n\n5.6 Reorder a corrgram\nWe can also re-order the variables.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order = \"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n5.7 Reordering a correlation matrix using hclust\nIf hclust is used, then the variables within the same cluster will be boxed in the plot.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order = \"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)\n\n\n\n\nThis comes to the end of this hands-on exercise. I have learned to different ways to visualize correlation matrix in R. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html",
    "title": "Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#learning-outcome",
    "title": "Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#getting-started",
    "title": "Heatmap for Visualising and Analysing Multivariate Data",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required libraries\nFirstly, let’s install and load the required packages:\n\ntidyverse: an opinionated collection of R packages designed for data import, data wrangling and data exploration\nseriation: provides the infrastructure for ordering objects with an implementation of several seriation/sequencing/ordination techniques to reorder matrices, dissimilarity matrices, and dendrograms.\nheatmaply: An object of class heatmapr includes all the needed information for producing a heatmap.\ndendextend: offers a set of functions for extending dendrogram objects in R, letting you visualize and compare trees of hierarchical clusterings.\n\n\npacman::p_load(tidyverse, seriation, heatmaply, dendextend)\n\n\n\n2.2 Importing the data\nWe’ll use the data of World Happines 2018 report for this hands-on exercise. The original data is stored in an excel file, and it’s been converted to a csv file for easy importing.\nLet’s start by importing the data.\n\nwh  &lt;- read_csv(\"../../Data/WHData-2018.csv\")\n\nThe data contains 156 rows and 12 columns:\n\n2 character variables:\n\nCountry\nRegion\n\n10 numerical variables:\n\nHappiness score\nWhisker-high\nWhisker-low\nDystopia\nGDP per capita\nSocial support\nHealthy life expectancy\nFreedom to make life choices\nGenerosity\nPerceptions of corruption\n\n\n\n\n2.3 Preparing the data\nTo create a heatmap, one of the pre-requisity is to use category as the row name instead of the default row number.\n\nrow.names(wh) &lt;- wh$Country\n\nIn this exercise, we will use country name as the row names.\n\n\n2.4 Transforming the data frame into a matrix\nAnother pre-requisity is that the data needs to be in a matrix format instead of dataframe.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#static-heatmap",
    "title": "Heatmap for Visualising and Analysing Multivariate Data",
    "section": "3. Static Heatmap",
    "text": "3. Static Heatmap\nLet’s first learn how to plot static heatmap.\n\n3.1 heatmap() of R Stats\nheatmap() function from base stats allows us to do that.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv = NA, Colv = NA)\n\n\n\n\nWe can plot the rows and columns as dendrograms like the example below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\nAs we noticed, the rows and columns are re-arranged in the second plot because the categories or variables belong to the same cluster have been grouped together.\nWe can also normalize the values by column to avoid mis-leading information.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale = \"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#interactive-heatmap",
    "title": "Heatmap for Visualising and Analysing Multivariate Data",
    "section": "4. Interactive Heatmap",
    "text": "4. Interactive Heatmap\nIn this section, we’ll create some interactive heatmaps using heatmaply package so we can interpret the information better.\n\n4.1 Working with heatmaply\n\nheatmaply(wh_matrix)\n\n\n\n\n\nWhen we mouse over the cells in the heatmap, the relevant information is displayed such as row category, column category and the respective value.\nWe can also select the columns that we are interested.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#data-trasformation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#data-trasformation",
    "title": "Heatmap for Visualising and Analysing Multivariate Data",
    "section": "5. Data trasformation",
    "text": "5. Data trasformation\nSimilar to the static heatmap, we can also normalize the values by columns so the data is comparable.\n\n5.1 Scaling method\nWe can transform all the columns to standard normal distribution using the code below.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n5.2 Normalising method\nMin-max transformation to bring the values into a range of 0 - 1, regardless of distribution.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n5.3 Percentising method\nRank the values by bringing the values to their empirical percentiles.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#clustering-algorithm",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#clustering-algorithm",
    "title": "Heatmap for Visualising and Analysing Multivariate Data",
    "section": "6. Clustering algorithm",
    "text": "6. Clustering algorithm\nheatmaply also supports a variety of hierarchical clustering algorithm.\n\n6.1 Manual approach\nWe can specify the type of hierachical clustering like the example below.\n\nheatmaply(normalize(wh_matrix[ , -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n6.2 Statistical approach\nWe first determine the best clustering method using the code below.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), \n             method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6765398\n2      unknown        ward.D2 0.6700807\n3      unknown         single 0.7219100\n4      unknown       complete 0.7259444\n5      unknown        average 0.8023959\n6      unknown       mcquitty 0.7031276\n7      unknown         median 0.7654802\n8      unknown       centroid 0.8122677\n\n\nWe can conclude that “centroid” method should be used as it has the highest optimum value.\nWe then use the scree plot to determine the number of clusters.\n\nwh_clust &lt;- hclust(wh_d, method = \"centroid\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nThe scree plot tells that k = 2 is the best.\nThen we can create the heatmap with the method and number of clusters chosen.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"centroid\",\n          k_row = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#seriation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#seriation",
    "title": "Heatmap for Visualising and Analysing Multivariate Data",
    "section": "7. Seriation",
    "text": "7. Seriation\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#working-with-colour-palettes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#working-with-colour-palettes",
    "title": "Heatmap for Visualising and Analysing Multivariate Data",
    "section": "8. Working with colour palettes",
    "text": "8. Working with colour palettes\nWe have been using the default color scale in the works above. However, we can customize the colors like the example below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#the-finishing-touch",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05c.html#the-finishing-touch",
    "title": "Heatmap for Visualising and Analysing Multivariate Data",
    "section": "9. The finishing touch",
    "text": "9. The finishing touch\nWe can further customize the heatmap like the example below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv = NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\n\n\n\nThis comes to the end of this hands-on exercise. I have learned to different ways to create heatmap in R. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html",
    "title": "Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to make parallel coordinates plot."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html#learning-outcome",
    "title": "Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to make parallel coordinates plot."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html#getting-started",
    "title": "Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required libraries\nFirstly, let’s install and load the required packages:\n\ntidyverse: an opinionated collection of R packages designed for data import, data wrangling and data exploration\nGGally: extends ‘ggplot2’ by adding several functions to reduce the complexity of combining geometric objects with transformed data.\nparallelPlot: Constructs a parallel coordinate plot for a data set with classes in last column.\n\n\npacman::p_load(tidyverse, GGally, parallelPlot)\n\n\n\n2.2 Importing the data\nWe’ll use the data of World Happines 2018 report for this hands-on exercise. The original data is stored in an excel file, and it’s been converted to a csv file for easy importing.\nLet’s start by importing the data.\n\nwh  &lt;- read_csv(\"../../Data/WHData-2018.csv\")\n\nThe data contains 156 rows and 12 columns:\n\n2 character variables:\n\nCountry\nRegion\n\n10 numerical variables:\n\nHappiness score\nWhisker-high\nWhisker-low\nDystopia\nGDP per capita\nSocial support\nHealthy life expectancy\nFreedom to make life choices\nGenerosity\nPerceptions of corruption"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html#plotting-static-parallel-coordinates-plot",
    "title": "Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "3. Plotting Static Parallel Coordinates Plot",
    "text": "3. Plotting Static Parallel Coordinates Plot\nn this section, we will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package.\n\n3.1 Plotting a simple parallel coordinates\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\nIt’s quite obvious to see that there are some outliers in the following columns:\n\nSocial support\nFreedom to make life choices\nGenerosity\nPercveptions of corruption\n\n\n\n3.2 Plotting a parallel coordinates with boxplot\nHowever, it’s quite difficult understand the distribution of the columns. We can overcome this by adding boxplots.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\nWe can now make more statistical inference from the plot.\n\n\n3.3 Parallel coordinates with facet\nWe can further break it down by facet to visualize the differences among different categories.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\nNow we have made the parallel coordinates plots for each region.\n\n\n3.4 Rotating x-axis text label\nLet’s now customize the plots a bit to make the x-axis labels easier to be read.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05d.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "4. Plotting Interactive Parallel Coordinates Plot: parallelPlot methods",
    "text": "4. Plotting Interactive Parallel Coordinates Plot: parallelPlot methods\nIn this section, we will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n4.1 The basic plot\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nWhen we click on any data point, the data from the same row is high lighted.\n\n\n4.2 Changing the colour scheme\nLet’s change the looks of the plot such as rotating the x-axis labels:\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n4.3 Parallel coordinates plot with histogram\nSimilarly, we can add histograms on the chart to view the distributions.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)\n\n\n\n\n\nThis comes to the end of this hands-on exercise. I have learned to make static and interactive parallel coordicates plots in R. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html",
    "title": "Treemap Visualisation with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to design treemap using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#learning-outcome",
    "title": "Treemap Visualisation with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to design treemap using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#getting-started",
    "title": "Treemap Visualisation with R",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required libraries\nFirstly, let’s install and load the required packages:\n\ntidyverse: an opinionated collection of R packages designed for data import, data wrangling and data exploration\ntreemap: offers great flexibility to draw treemaps.\ntreemapify: a ggplot2 extension to draw treemaps.\n\n\npacman::p_load(tidyverse, treemap, treemapify)\n\n\n\n2.2 Importing the data\nIn this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal of Urban Redevelopment Authority (URA).\nLet’s start by importing the data.\n\nrealis2018  &lt;- read_csv(\"../../Data/realis2018.csv\")\n\nThe data contains 156 rows and 12 columns:\n\n12 character variables\n8 numerical variables\n\n\n\n2.3 Preparing the data\nTo prepare the data for treemaps, we need to transform the data in the following ways:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,\n           `Planning Region`, \n           `Planning Area`, \n           `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#designing-treemap-with-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#designing-treemap-with-treemap-package",
    "title": "Treemap Visualisation with R",
    "section": "3. Designing Treemap with treemap Package",
    "text": "3. Designing Treemap with treemap Package\nIn this section, we will only explore the major arguments for designing elegant and yet truthful treemaps.\n\n3.1 Designing a static treemap\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n3.2 Using the basic arguments\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nIn the treemap above, the size of the cells indicate the number of units sold in each planning area. The bigger the size, the more units sold.\nHowever, the color scheme used does not reflect the median unit price of the condos because it doesn’t tell us which color represent higher unit price or which color represents lower unit price.\n\n\n3.3 Working with vColor and type arguments\nThis can be overcomed by adding type argument like the example below:\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThe intensity of the color can now tell us that the darker the color is, the higher the price is.\nWe can change the color scheme like the example below:\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThe type argument can take another value as “manual” where the value range is mapped linearly to the colour palette. For example,\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nNow we can see that the values of the unit price covers the entire color range.\nIf we just want to see a single color, then we can specify the palette as follows:\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n3.4 Working with algorithm argument\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n3.5 Using sortID\nWe can also sort the cells as the way we prefer, from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nNow, the cells are sorted by median transacted price."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#designing-treemap-using-treemapify-package",
    "title": "Treemap Visualisation with R",
    "section": "4. Designing Treemap using treemapify Package",
    "text": "4. Designing Treemap using treemapify Package\nIn this section, you will learn how to designing treemaps closely resemble treemaps designing in previous section by using treemapify.\n\n4.1 Designing a basic treemap\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n4.2 Defining hierarchy\nGroup by Planning Region.\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\nGroup by Planning Area.\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\nAdding boundary line.\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#designing-interactive-treemap-using-d3treer",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05e.html#designing-interactive-treemap-using-d3treer",
    "title": "Treemap Visualisation with R",
    "section": "5. Designing Interactive Treemap using d3treeR",
    "text": "5. Designing Interactive Treemap using d3treeR\nIn this section, we’ll learn how to make interactive treemaps using d3treeR package.\n\n5.1 Installing d3treeR package\n\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\")\n\n\nlibrary(d3treeR)\n\n\n\n5.2 Designing An Interactive Treemap\nWe are now ready to create an interactive treemap.\nStep 1:\n\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nStep 2:\n\nd3tree(tm,rootname = \"Singapore\" )\n\n\n\n\n\nWhen we click on any cells in the treemap above, it’ll zoom into that particular planning area.\nThis comes to the end of this hands-on exercise. I have learned to make static and interactive treemaps plots in R. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Be Weatherwise or Otherwise",
    "section": "",
    "text": "This is the take home exercise 3 of ISSS608 Visual Analytics and Applications. In this exercise, we are instructed to analyze the historical weather data downloaded from Meteorological Service Singapore website to understand the weather change trend in Singapore.\nMeteorological Service Singapore website provides the historical daily weather indicators for all the 63 stations in Singapore that can be traced back to January 1980. The weather indicators that are available includes:\n\nDaily Rainfall Total (mm)\nHighest 30 min Rainfall (mm)\nHighest 60 min Rainfall (mm)\nHighest 120 min Rainfall (mm)\nMean Temperature (°C)\nMaximum Temperature (°C)\nMinimum Temperature (°C)\nMean Wind Speed (km/h)\nMax Wind Speed (km/h)\n\nFor the interest of this exercise, we’ll focus on the daily rainfall column, and use the visualization techniques learned in class to study the data patterns.\n\n\n\nMeteorological Service Singapore website allows us to download the data in csv format by year and month. In each csv file, there are daily records of the above mentioned weather information. To keep the scope of this exercise simpler, we downloaded the data from Sentosa Island station for the following time periods:\n\nYear 1983: January to December\nYear 1993: January to December\nYear 2003: January to December\nYear 2013: January to December\nYear 2023: January to December\n\nTherefore, a total of 60 csv files were obtained."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#setting-the-scene",
    "title": "Be Weatherwise or Otherwise",
    "section": "",
    "text": "This is the take home exercise 3 of ISSS608 Visual Analytics and Applications. In this exercise, we are instructed to analyze the historical weather data downloaded from Meteorological Service Singapore website to understand the weather change trend in Singapore.\nMeteorological Service Singapore website provides the historical daily weather indicators for all the 63 stations in Singapore that can be traced back to January 1980. The weather indicators that are available includes:\n\nDaily Rainfall Total (mm)\nHighest 30 min Rainfall (mm)\nHighest 60 min Rainfall (mm)\nHighest 120 min Rainfall (mm)\nMean Temperature (°C)\nMaximum Temperature (°C)\nMinimum Temperature (°C)\nMean Wind Speed (km/h)\nMax Wind Speed (km/h)\n\nFor the interest of this exercise, we’ll focus on the daily rainfall column, and use the visualization techniques learned in class to study the data patterns.\n\n\n\nMeteorological Service Singapore website allows us to download the data in csv format by year and month. In each csv file, there are daily records of the above mentioned weather information. To keep the scope of this exercise simpler, we downloaded the data from Sentosa Island station for the following time periods:\n\nYear 1983: January to December\nYear 1993: January to December\nYear 2003: January to December\nYear 2013: January to December\nYear 2023: January to December\n\nTherefore, a total of 60 csv files were obtained."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#understanding-the-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#understanding-the-data",
    "title": "Be Weatherwise or Otherwise",
    "section": "2. Understanding the Data",
    "text": "2. Understanding the Data\n\n2.1 Installing and loading the required libraries\nIn this exercise, we’ll make use the following R packages:\n\ntidyverse: an opinionated collection of R packages designed for data import, data wrangling and data exploration\n\nLet’s use the code chunk below to load the required R packages.\n\npacman::p_load(tidyverse, ggstatsplot, ggridges, ggdist)\n\n\n\n2.2 Importing the data\nSince the data is distributed in different files, let’s first create a program to loop through all the csv files, and combine the rainfall data into one dataframe.\n\n# Set folder path\nfolder_path &lt;- \"../../Data/Weather_Sentosa\"\n\n# List all CSV files in the folder\ncsv_files &lt;- list.files(path = folder_path, \n                        pattern = \"\\\\.csv$\")\n\n# Initialize an empty list to store data frames\ndata_list &lt;- list()\n\n# Loop through each CSV file and import the data\nfor (file in csv_files) {\n  # Construct the full path to the CSV file\n  file_path &lt;- file.path(folder_path, file)\n  \n  # Read the CSV file and store it in the list\n  data &lt;- read_csv(file_path,\n                   col_select = c(`Year`, `Month`, `Day`, `Daily Rainfall Total (mm)`),\n                   na = \"-\"\n                   )\n  \n  # Store the data frame in the list\n  data_list[[file]] &lt;- data\n}\n\n# Combine all the data into one dataframe\nRF_data &lt;- bind_rows(data_list)\n\n# Save the dataframe into a csv file\nwrite_csv(RF_data, \"../../Data/Weather_Sentosa/Weather_Sentosa_RF.csv\")\n\nThen, let’s import the rainfall data from the csv file.\n\nRF_data &lt;- read_csv(\"../../Data/Weather_Sentosa/Weather_Sentosa_RF.csv\")\n\nWe have now combined all the data into one single dataframe called RF_data. There are 1,825 rows and 4 numerical variables as listed below:\n\nYear\nMonth\nDay\nDaily Rainfall Total (mm)\n\n\n\n2.3 Preparing Data\nTo prepare the data for the plots in the later sections, we’ll convert the first 3 columns (i.e., Year, Month, Day) into factor columns.\n\nRF_data$Year &lt;- as.character(RF_data$Year)\nRF_data$Month &lt;- as.character(RF_data$Month)\nRF_data$Day &lt;- as.character(RF_data$Day)\n\nRF_data$Year &lt;- factor(RF_data$Year, levels = c(\"1983\", \"1993\", \"2003\", \"2013\", \"2023\"))\n\nRF_data$Month &lt;- factor(RF_data$Month, levels = c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"))\n\nRF_data$Day &lt;- factor(RF_data$Day, levels = c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-visualization",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-visualization",
    "title": "Be Weatherwise or Otherwise",
    "section": "3. Data Visualization",
    "text": "3. Data Visualization\nIn this section, we’ll make use of the visualization techniques learned in class to study the trend of rainfall in Singapore.\n\n3.1 Rainfall trend over the years\nSince we have the rainfall data for 5 years which are 1983, 1993, 2003, 2013 and 2023. It’d be interesting to see if there is any temporal trend from 1983 to 2023.\nTo achieve this, we’ll first compute the average rainfall for each month per year, and perform one-way ANOVA test to check the significance of the differences.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nRF_data_monthly &lt;- RF_data %&gt;%\n  group_by(Year, Month) %&gt;%\n  summarise_at(vars(`Daily Rainfall Total (mm)`),\n               funs(mean(.,na.rm = TRUE)))\n\nggbetweenstats(\n  data = RF_data_monthly,\n  x = Year, \n  y = `Daily Rainfall Total (mm)`,\n  type = \"np\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe plot shows that there are some differences across the years in terms of the daily total rainfall amount. However, they are not statistically significant at 5% significance level as the p value is greater than 0.05. Therefore, we can conclude that no significant changes observed in total daily rainfall from 1983 to 2023 in general.\n\n\n\n\n3.2 Breaking down by month\nNext, let’s study the data pattern for each month to see if there is really no significant trend across years.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot() + \n  geom_line(data=RF_data_monthly,\n            aes(x=Year, \n                y=`Daily Rainfall Total (mm)`,\n                group = Month), \n            colour=\"darkgreen\") +\n  facet_grid(~Month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Average Daily Rainfall (mm) by Month from 1983 to 2023\") +\n  xlab(\"\") +\n  ylab(\"Average Daily Rainfall (mm)\") +\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe plot echoed the observation we made in the previous section that there isn’t significant trend in the rainfall amount from 1983 to 2023, even after breaking down by month except February. The rainfall amount in February displayed an upward trend from 1983 to 2023.\n\n\n\n\n3.3 Seasonal trend of rainfall\nIn this section, we’ll investigate if there is any seasonal trend exhibited in the data.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(RF_data_monthly, \n       aes(Month, \n           Year, \n           fill = `Daily Rainfall Total (mm)`)) +\n  geom_tile(color = \"white\", \n          size = 0.1) +\n  coord_equal() +\n  scale_fill_gradient(name = \"Average Daily Rainfall (mm)\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  labs(x = NULL,\n       y = NULL,\n       title = \"Average Daily Rainfall (mm) by Month\") +\n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) ) +\n  scale_y_discrete(limits = rev(levels(as.factor(RF_data_monthly$Year))))\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nContradicts to what we hypothesized, there is no clear cut of wet months and dry months from the data collected at Sentosa Island station. Although there is generally more rainfall in year end than in the middle of the year, we can’t see a clear seasonality pattern across the years.\nFor example, the raining season seems to start from July in 1983, October in 1993, December in 2003, September in 2013 and November in 2023. It could be due to the weather station I have chosen for this exercise. Sentosa Island is closer to the sea, and it’s probably more influenced by the sea wind."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conclusion",
    "title": "Be Weatherwise or Otherwise",
    "section": "4. Conclusion",
    "text": "4. Conclusion\nThrough the study of the historical rainfall data collected at Sentosa Island station across 5 years from 1983 to 2023, it’s interesting to see that\n\nIt seems that the rainfall amount increased across the years, but the increment is not statistically significant. We have investigated the differences both by year and by month, the same observations were made.\nContradicts to what we hypothesized, the rainfall amount didn’t display a clear seasonal trend. Although it seems that it rains more at the end of the year than the middle of the year.\n\nThis comes to the end of my take-home exercise 3. Hope you enjoyed reading my explorations and findings. See you in the next take-home exercise 🥰"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-class_Ex07",
    "section": "",
    "text": "pacman::p_load(sf, terra, gstat, tmap, viridis, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#loading-r-packages",
    "title": "In-class_Ex07",
    "section": "",
    "text": "pacman::p_load(sf, terra, gstat, tmap, viridis, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#importing-data",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#importing-data",
    "title": "In-class_Ex07",
    "section": "Importing data",
    "text": "Importing data\nFirstly, we import the data which includes the longitude and latitude of the rainfall stations.\n\nrfstation &lt;- read_csv(\"../../Data/aspatial/RainfallStation.csv\")\n\nNext, we import the data which includes the daily rainfall amount collected from all the rainfall stations. For the interest of this exercise, we are interested in the monthly total rainfall at different stations. Therefore, we summarize the rainfall amount at each station while importing the data.\n\nrfdata &lt;- read_csv(\"../../Data/aspatial/DAILYDATA_202402.csv\") %&gt;%\n  select(c(1, 5)) %&gt;%\n  group_by(Station) %&gt;%\n  summarise(MONTHSUM = sum(`Daily Rainfall Total (mm)`)) %&gt;%\n  ungroup()\n\n\nrfdata &lt;- rfdata %&gt;%\n  left_join(rfstation)\n\nConvert the geometry from decimal degree (crs = 4326) into meters (crs = 3414)\n\nrfdata_sf &lt;- st_as_sf(rfdata,\n                      coords = c(\"Longitude\",\n                                 \"Latitude\"),\n                      crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\nImport map boundary data.\n\nmpsz2019 &lt;- st_read(dsn = \"../../Data/geospatial\",\n                    layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source `D:\\MITB_SunYP\\ISSS608\\Data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\ntm_shape(mpsz2019) +\n  tm_borders() +\ntm_shape(rfdata_sf) +\n  tm_dots(col = \"MONTHSUM\")\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\nmpsz2019\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\n(ymin - xmin)/50 –&gt; prefer 50x50 meter grid or 100x100 meter grid?\n\ngrid &lt;- terra::rast(mpsz2019,\n                    nrows = 690,\n                    ncols = 1075)\n\n# xy &lt;- terra::xyFromCell()"
  },
  {
    "objectID": "Data/geospatial/MPSZ-2019.html",
    "href": "Data/geospatial/MPSZ-2019.html",
    "title": "ISSS608",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "title": "Prototyping Modules for Visual Analytics Shiny Application",
    "section": "",
    "text": "This is the take home exercise 4 of ISSS608 Visual Analytics and Applications. In this exercise, we are instructed to develop the prototype for our group Shiny app. Each member of our team needs to pick a module in our Shiny app, and work out the prototype for that module.\nOur team chose the topic to study the climate impact in Singapore using the weather data downloaded from Meteorological Service Singapore website and the weekly dengue cases from SGCharts: Outbreak.\nThe module I have chosen for this take home exercise is to develop an explanatory model to test the impact of the weather data (i.e., temperature, rainfall and wind) on the occurrence of dengue cases in Singapore.\nFor the interest of this project, we are going to explore the data on a weekly basis at the national level."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "title": "In-class_Ex09",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#loading-r-packages",
    "title": "In-class_Ex09",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#importing-network-data-from-files",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#importing-network-data-from-files",
    "title": "In-class_Ex09",
    "section": "Importing network data from files",
    "text": "Importing network data from files\n\nGAStech_nodes &lt;- read_csv(\"../../Data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"../../Data/GAStech_email_edge-v2.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#preparing-the-data",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#preparing-the-data",
    "title": "In-class_Ex09",
    "section": "Preparing the data",
    "text": "Preparing the data\nCreate two new columns:\n\nconvert SentDate to a date variable, and store in a new variable called SendDate\nCreate Weekday from SendDate\n\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\nFilter the edge data for work related emails, and aggregate the data by source, target, and weekday.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#using-tbl_graph-to-build-tidygraph-data-model",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#using-tbl_graph-to-build-tidygraph-data-model",
    "title": "In-class_Ex09",
    "section": "Using tbl_graph() to build tidygraph data model",
    "text": "Using tbl_graph() to build tidygraph data model\nArrange the data in tibble format.\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\nTo check the data structure.\n\nGAStech_graph \n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#plotting-a-basic-network-graph",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#plotting-a-basic-network-graph",
    "title": "In-class_Ex09",
    "section": "Plotting a basic network graph",
    "text": "Plotting a basic network graph\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#changing-the-default-network-graph-theme",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#changing-the-default-network-graph-theme",
    "title": "In-class_Ex09",
    "section": "Changing the default network graph theme",
    "text": "Changing the default network graph theme\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#changing-the-coloring-of-the-plot",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#changing-the-coloring-of-the-plot",
    "title": "In-class_Ex09",
    "section": "Changing the coloring of the plot",
    "text": "Changing the coloring of the plot\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#fruchterman-and-reingold-layout",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#fruchterman-and-reingold-layout",
    "title": "In-class_Ex09",
    "section": "Fruchterman and Reingold layout",
    "text": "Fruchterman and Reingold layout\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#modifying-network-nodes",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#modifying-network-nodes",
    "title": "In-class_Ex09",
    "section": "Modifying network nodes",
    "text": "Modifying network nodes\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#modifying-edges",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#modifying-edges",
    "title": "In-class_Ex09",
    "section": "Modifying edges",
    "text": "Modifying edges\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width = Weight), \n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#working-with-facet_edges",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#working-with-facet_edges",
    "title": "In-class_Ex09",
    "section": "Working with facet_edges()",
    "text": "Working with facet_edges()\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width = Weight), \n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#working-with-facet_nodes",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#working-with-facet_nodes",
    "title": "In-class_Ex09",
    "section": "Working with facet_nodes()",
    "text": "Working with facet_nodes()\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width = Weight), \n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#computing-centrality-indices",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#computing-centrality-indices",
    "title": "In-class_Ex09",
    "section": "Computing centrality indices",
    "text": "Computing centrality indices\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width = Weight), \n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size = betweenness_centrality))\ng + theme_graph()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#setting-the-scene",
    "title": "Prototyping Modules for Visual Analytics Shiny Application",
    "section": "",
    "text": "This is the take home exercise 4 of ISSS608 Visual Analytics and Applications. In this exercise, we are instructed to develop the prototype for our group Shiny app. Each member of our team needs to pick a module in our Shiny app, and work out the prototype for that module.\nOur team chose the topic to study the climate impact in Singapore using the weather data downloaded from Meteorological Service Singapore website and the weekly dengue cases from SGCharts: Outbreak.\nThe module I have chosen for this take home exercise is to develop an explanatory model to test the impact of the weather data (i.e., temperature, rainfall and wind) on the occurrence of dengue cases in Singapore.\nFor the interest of this project, we are going to explore the data on a weekly basis at the national level."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#understanding-the-data",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#understanding-the-data",
    "title": "Prototyping Modules for Visual Analytics Shiny Application",
    "section": "2. Understanding the Data",
    "text": "2. Understanding the Data\n\n2.1 Installing and loading the required libraries\n\npacman::p_load(tidyverse, lubridate, caret, performance, ggstatsplot)\n\n\n\n2.2 Importing the data\n\n2.2.1 Weather data\n\nweather &lt;- read_csv(\"../../Data/clean_climate_data.csv\", na = \".\")\n\nhead(weather, n=10)\n\n# A tibble: 10 × 13\n   Station     Year Month   Day daily_rainfall highest_30m_rainfall\n   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;                &lt;dbl&gt;\n 1 Paya Lebar  2003     1     1           31                     NA\n 2 Paya Lebar  2003     1     2           28                     NA\n 3 Paya Lebar  2003     1     3            1.8                   NA\n 4 Paya Lebar  2003     1     4            3.3                   NA\n 5 Paya Lebar  2003     1     5            9.3                   NA\n 6 Paya Lebar  2003     1     6            0.5                   NA\n 7 Paya Lebar  2003     1     7           19.2                   NA\n 8 Paya Lebar  2003     1     8           26                     NA\n 9 Paya Lebar  2003     1     9            0                     NA\n10 Paya Lebar  2003     1    10            0                     NA\n# ℹ 7 more variables: highest_60m_rainfall &lt;dbl&gt;, highest_120m_rainfall &lt;dbl&gt;,\n#   mean_temp &lt;dbl&gt;, max_temp &lt;dbl&gt;, min_temp &lt;dbl&gt;, mean_wind &lt;dbl&gt;,\n#   max_wind &lt;dbl&gt;\n\n\n\n\n2.2.2 Dengue data\n\ndengue &lt;- read_csv(\"../../Data/weekly_dengue_cases.csv\")\n\nhead(dengue, n=10)\n\n# A tibble: 10 × 3\n    Year  WkNo Cases\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2013    20   611\n 2  2013    21   640\n 3  2013    22   746\n 4  2013    23   814\n 5  2013    24   810\n 6  2013    25   853\n 7  2013    26   806\n 8  2013    27   678\n 9  2013    28   541\n10  2013    29   391\n\n\n\n\n\n2.3 Preparing the data\n\n2.3.1 Weather Data\nThe weather data downloaded from Meteorological Service Singapore website contains the weather information at each weather station. Hence, we use the code chunk below to aggregate the data at national level\n\navg_daily_rainfall: average daily rainfall among all stations\nmax_highest_30m_rainfall: maximum highest 30m rainfall among all stations\nmax_highest_60m_rainfall: maximum highest 60m rainfall among all stations\nmax_highest_120m_rainfall: maximum highest 120m rainfall among all stations\navg_mean_temp: average temperature among all stations\nmax_max_temp: maximum of highest temperature among all stations\nmin_min_temp: minimum of lowest temperature among all stations\navg_mean_wind: average wind among all stations\nmax_max_wind: maximum of maximum wind among all stations\n\n\nweather_group &lt;- weather %&gt;%\n  group_by(Year, Month, Day) %&gt;%\n  summarise(avg_daily_rainfall = mean(daily_rainfall, na.rm = TRUE),\n            max_highest_30m_rainfall = max(highest_30m_rainfall, na.rm = TRUE),\n            max_highest_60m_rainfall = max(highest_60m_rainfall, na.rm = TRUE),\n            max_highest_120m_rainfall = max(highest_120m_rainfall, na.rm = TRUE),\n            avg_mean_temp = mean(mean_temp, na.rm = TRUE),\n            max_max_temp = max(max_temp, na.rm = TRUE),\n            min_min_temp = min(min_temp, na.rm = TRUE),\n            avg_mean_wind = mean(mean_wind, na.rm = TRUE),\n            max_max_wind = max(max_wind, na.rm = TRUE)) %&gt;%\n  ungroup()\n\nsummary(weather_group)\n\n      Year          Month             Day        avg_daily_rainfall \n Min.   :2003   Min.   : 1.000   Min.   : 1.00   Min.   :  0.00000  \n 1st Qu.:2008   1st Qu.: 4.000   1st Qu.: 8.00   1st Qu.:  0.06667  \n Median :2013   Median : 7.000   Median :16.00   Median :  2.26056  \n Mean   :2013   Mean   : 6.523   Mean   :15.73   Mean   :  6.90035  \n 3rd Qu.:2018   3rd Qu.:10.000   3rd Qu.:23.00   3rd Qu.:  9.38194  \n Max.   :2023   Max.   :12.000   Max.   :31.00   Max.   :198.02500  \n max_highest_30m_rainfall max_highest_60m_rainfall max_highest_120m_rainfall\n Min.   :-Inf             Min.   : -Inf            Min.   : -Inf            \n 1st Qu.:-Inf             1st Qu.: -Inf            1st Qu.: -Inf            \n Median :-Inf             Median : -Inf            Median : -Inf            \n Mean   :-Inf             Mean   : -Inf            Mean   : -Inf            \n 3rd Qu.: 9.2             3rd Qu.: 10.2            3rd Qu.: 10.8            \n Max.   :67.0             Max.   :102.6            Max.   :124.4            \n avg_mean_temp    max_max_temp    min_min_temp   avg_mean_wind   \n Min.   :22.94   Min.   :24.30   Min.   : 0.00   Min.   : 2.800  \n 1st Qu.:27.02   1st Qu.:32.10   1st Qu.:22.90   1st Qu.: 6.506  \n Median :27.80   Median :33.20   Median :23.50   Median : 7.656  \n Mean   :27.76   Mean   :32.89   Mean   :23.56   Mean   : 8.130  \n 3rd Qu.:28.59   3rd Qu.:34.00   3rd Qu.:24.20   3rd Qu.: 9.300  \n Max.   :30.65   Max.   :38.00   Max.   :27.50   Max.   :21.900  \n  max_max_wind   \n Min.   :  9.40  \n 1st Qu.: 33.30  \n Median : 41.00  \n Mean   : 42.88  \n 3rd Qu.: 49.70  \n Max.   :138.60  \n\n\nTwo new columns need to be created before we can aggregate the data at week level:\n\ndate: a date variable created from Year, Month and Day columns\nwk_no: calculate the week number using the date column\n\n\nweather_group &lt;- weather_group %&gt;%\n  mutate('date' = make_date(year = Year, month = Month, day = Day)) %&gt;%\n  mutate('wk_no' = isoweek(ymd(date)))\n\nWe can now aggregate the data by week:\n\navg_daily_rainfall: average rainfall in a week. For some reasons, average and sum can’t be calculated under one group_by() command. Hence, the calculation of average rainfall and total rainfall have been divided in two steps.\ntot_daily_rainfall: total rainfall in a week\nmax_highest_30m_rainfall: maximum highest 30m rainfall in a week\nmax_highest_60m_rainfall: maximum highest 60m rainfall in a week\nmax_highest_120m_rainfall: maximum highest 120m rainfall in a week\navg_mean_temp: average temperature in a week\nmax_max_temp: maximum of highest daily temperature in a week\nmin_min_temp: minimum of lowest daily temperature in a week\navg_mean_wind: average wind in a week\nmax_max_wind: maximum of maximum daily wind in a week\n\n\nweather_group_wk &lt;- weather_group %&gt;%\n  group_by(Year, wk_no) %&gt;%\n  summarise(tot_daily_rainfall = sum(avg_daily_rainfall),\n            max_highest_30m_rainfall = max(max_highest_30m_rainfall),\n            max_highest_60m_rainfall = max(max_highest_60m_rainfall),\n            max_highest_120m_rainfall = max(max_highest_120m_rainfall),\n            avg_mean_temp = mean(avg_mean_temp),\n            max_max_temp = max(max_max_temp),\n            min_min_temp = min(min_min_temp),\n            avg_mean_wind = mean(avg_mean_wind),\n            max_max_wind = max(max_max_wind)) %&gt;%\n  ungroup()\n\nweather_group_wk &lt;- weather_group %&gt;%\n  group_by(Year, wk_no) %&gt;%\n  summarise(avg_daily_rainfall = mean(avg_daily_rainfall)) %&gt;%\n  left_join(weather_group_wk, by = join_by(Year, wk_no)) %&gt;%\n  ungroup()\n\nsummary(weather_group_wk)\n\n      Year          wk_no       avg_daily_rainfall tot_daily_rainfall\n Min.   :2003   Min.   : 1.00   Min.   : 0.000     Min.   :  0.00    \n 1st Qu.:2008   1st Qu.:14.00   1st Qu.: 3.041     1st Qu.: 21.36    \n Median :2013   Median :27.00   Median : 5.923     Median : 41.39    \n Mean   :2013   Mean   :26.69   Mean   : 6.947     Mean   : 48.11    \n 3rd Qu.:2018   3rd Qu.:40.00   3rd Qu.: 9.462     3rd Qu.: 66.16    \n Max.   :2023   Max.   :53.00   Max.   :71.681     Max.   :372.31    \n max_highest_30m_rainfall max_highest_60m_rainfall max_highest_120m_rainfall\n Min.   :-Inf             Min.   : -Inf            Min.   :  -Inf           \n 1st Qu.:-Inf             1st Qu.: -Inf            1st Qu.:  -Inf           \n Median :-Inf             Median : -Inf            Median :  -Inf           \n Mean   :-Inf             Mean   : -Inf            Mean   :  -Inf           \n 3rd Qu.:34.2             3rd Qu.: 44.4            3rd Qu.: 49.25           \n Max.   :67.0             Max.   :102.6            Max.   :124.40           \n avg_mean_temp    max_max_temp    min_min_temp   avg_mean_wind   \n Min.   :23.85   Min.   :28.00   Min.   : 0.00   Min.   : 4.668  \n 1st Qu.:27.18   1st Qu.:33.70   1st Qu.:22.10   1st Qu.: 6.766  \n Median :27.78   Median :34.30   Median :22.50   Median : 7.787  \n Mean   :27.76   Mean   :34.31   Mean   :22.46   Mean   : 8.135  \n 3rd Qu.:28.36   3rd Qu.:35.00   3rd Qu.:23.00   3rd Qu.: 9.017  \n Max.   :30.16   Max.   :38.00   Max.   :24.80   Max.   :19.214  \n  max_max_wind  \n Min.   : 23.4  \n 1st Qu.: 45.0  \n Median : 56.5  \n Mean   : 58.4  \n 3rd Qu.: 68.3  \n Max.   :138.6  \n\n\nWe can save the weekly weather data in csv file format for future reference.\n\nwrite_csv(weather_group_wk, \"../../Data/clean_climate_data_by_week.csv\")\n\n\n\n2.3.2 Join Dengue Data with Weekly Weather Data\nAs there are more records in weather data, we will perform a left join using dengue data.\n\ndengue_weather_wk &lt;- dengue %&gt;%\n  left_join(weather_group_wk, by = join_by(Year == Year, WkNo == wk_no))\n\nsummary(dengue_weather_wk)\n\n      Year           WkNo           Cases        avg_daily_rainfall\n Min.   :2013   Min.   : 1.00   Min.   :  24.0   Min.   : 0.000    \n 1st Qu.:2015   1st Qu.:15.00   1st Qu.:  78.0   1st Qu.: 2.720    \n Median :2017   Median :27.50   Median : 229.5   Median : 5.148    \n Mean   :2017   Mean   :27.13   Mean   : 291.7   Mean   : 5.976    \n 3rd Qu.:2019   3rd Qu.:40.00   3rd Qu.: 379.5   3rd Qu.: 8.486    \n Max.   :2020   Max.   :53.00   Max.   :1792.0   Max.   :27.621    \n                                                 NA's   :2         \n tot_daily_rainfall max_highest_30m_rainfall max_highest_60m_rainfall\n Min.   :  0.00     Min.   : -Inf            Min.   :  -Inf          \n 1st Qu.: 19.04     1st Qu.:20.55            1st Qu.: 24.15          \n Median : 36.03     Median :32.40            Median : 41.60          \n Mean   : 41.91     Mean   : -Inf            Mean   :  -Inf          \n 3rd Qu.: 59.40     3rd Qu.:40.00            3rd Qu.: 55.85          \n Max.   :193.35     Max.   :65.20            Max.   :102.60          \n NA's   :2          NA's   :2                NA's   :2               \n max_highest_120m_rainfall avg_mean_temp    max_max_temp   min_min_temp  \n Min.   : -Inf             Min.   :24.56   Min.   :31.0   Min.   : 0.00  \n 1st Qu.: 26.2             1st Qu.:27.53   1st Qu.:34.1   1st Qu.:22.10  \n Median : 46.4             Median :28.09   Median :34.7   Median :22.60  \n Mean   : -Inf             Mean   :28.07   Mean   :34.6   Mean   :22.41  \n 3rd Qu.: 64.0             3rd Qu.:28.68   3rd Qu.:35.2   3rd Qu.:23.10  \n Max.   :122.8             Max.   :30.09   Max.   :37.5   Max.   :24.80  \n NA's   :2                 NA's   :2       NA's   :2      NA's   :2      \n avg_mean_wind     max_max_wind   \n Min.   : 5.442   Min.   : 35.30  \n 1st Qu.: 7.070   1st Qu.: 55.40  \n Median : 8.057   Median : 63.40  \n Mean   : 8.348   Mean   : 66.63  \n 3rd Qu.: 9.255   3rd Qu.: 73.17  \n Max.   :14.846   Max.   :138.60  \n NA's   :2        NA's   :2       \n\n\nRemove the rows with no weather data.\n\ndengue_weather_wk &lt;- dengue_weather_wk[complete.cases(dengue_weather_wk),]\n\nsummary(dengue_weather_wk)\n\n      Year           WkNo           Cases         avg_daily_rainfall\n Min.   :2013   Min.   : 1.00   Min.   :  24.00   Min.   : 0.000    \n 1st Qu.:2015   1st Qu.:14.75   1st Qu.:  77.75   1st Qu.: 2.720    \n Median :2017   Median :27.00   Median : 229.50   Median : 5.148    \n Mean   :2017   Mean   :27.00   Mean   : 291.68   Mean   : 5.976    \n 3rd Qu.:2019   3rd Qu.:40.00   3rd Qu.: 378.50   3rd Qu.: 8.486    \n Max.   :2020   Max.   :52.00   Max.   :1792.00   Max.   :27.621    \n tot_daily_rainfall max_highest_30m_rainfall max_highest_60m_rainfall\n Min.   :  0.00     Min.   : -Inf            Min.   :  -Inf          \n 1st Qu.: 19.04     1st Qu.:20.55            1st Qu.: 24.15          \n Median : 36.03     Median :32.40            Median : 41.60          \n Mean   : 41.91     Mean   : -Inf            Mean   :  -Inf          \n 3rd Qu.: 59.40     3rd Qu.:40.00            3rd Qu.: 55.85          \n Max.   :193.35     Max.   :65.20            Max.   :102.60          \n max_highest_120m_rainfall avg_mean_temp    max_max_temp   min_min_temp  \n Min.   : -Inf             Min.   :24.56   Min.   :31.0   Min.   : 0.00  \n 1st Qu.: 26.2             1st Qu.:27.53   1st Qu.:34.1   1st Qu.:22.10  \n Median : 46.4             Median :28.09   Median :34.7   Median :22.60  \n Mean   : -Inf             Mean   :28.07   Mean   :34.6   Mean   :22.41  \n 3rd Qu.: 64.0             3rd Qu.:28.68   3rd Qu.:35.2   3rd Qu.:23.10  \n Max.   :122.8             Max.   :30.09   Max.   :37.5   Max.   :24.80  \n avg_mean_wind     max_max_wind   \n Min.   : 5.442   Min.   : 35.30  \n 1st Qu.: 7.070   1st Qu.: 55.40  \n Median : 8.057   Median : 63.40  \n Mean   : 8.348   Mean   : 66.63  \n 3rd Qu.: 9.255   3rd Qu.: 73.17  \n Max.   :14.846   Max.   :138.60  \n\n\nWe can save the joined data in csv file format for future reference.\n\nwrite_csv(dengue_weather_wk, \"../../Data/dengue_climate_joined_by_week.csv\")\n\n\n\n2.3.3 Data Transformation\nWe’ll then perform the following transformations and add the corresponding transformed columns in the dataset:\n\nlog transformation: log1p() is used instead of log() is to deal with rows having value of 0\nstandardization\n\n\ndengue_weather_wk_tf &lt;- dengue_weather_wk %&gt;%\n  mutate(log_cases = log1p(Cases),\n         log_avg_daily_rainfall = log1p(avg_daily_rainfall),\n         log_tot_daily_rainfall = log1p(tot_daily_rainfall),\n         log_max_highest_30m_rainfall = log1p(max_highest_30m_rainfall),\n         log_max_highest_60m_rainfall = log1p(max_highest_60m_rainfall),\n         log_max_highest_120m_rainfall = log1p(max_highest_120m_rainfall),\n         log_avg_mean_temp = log1p(avg_mean_temp),\n         log_max_max_temp = log1p(max_max_temp),\n         log_min_min_temp = log1p(min_min_temp),\n         log_avg_mean_wind = log1p(avg_mean_wind),\n         log_max_max_wind = log1p(max_max_wind),\n         z_cases = scale(Cases),\n         z_avg_daily_rainfall = scale(avg_daily_rainfall),\n         z_tot_daily_rainfall = scale(tot_daily_rainfall),\n         z_avg_mean_temp = scale(avg_mean_temp),\n         z_max_max_temp = scale(max_max_temp),\n         z_min_min_temp = scale(min_min_temp),\n         z_avg_mean_wind = scale(avg_mean_wind),\n         z_max_max_wind = scale(max_max_wind))\n\nNext we use the preprocess() function from caret package to perform min-max transformation on the data.\n\nminmax_data &lt;- dengue_weather_wk %&gt;%\n  select(-c(\"max_highest_30m_rainfall\", \"max_highest_60m_rainfall\", \"max_highest_120m_rainfall\"))\n\n#minmax_preprocess &lt;- preProcess(minmax_data, method = c(\"range\"))\n\nminmax_preprocess &lt;- preProcess(minmax_data, method = list(range = names(minmax_data)[3:10]))\n\nminmax_result &lt;- predict(minmax_preprocess, minmax_data)\n\ncolnames(minmax_result) &lt;- c(\"Year\",\n                             \"WkNo\",\n                             \"mm_Cases\",\n                             \"mm_avg_daily_rainfall\",\n                             \"mm_tot_daily_rainfall\",\n                             \"mm_avg_mean_temp\",\n                             \"mm_max_max_temp\",\n                             \"mm_min_min_temp\",\n                             \"mm_avg_mean_wind\",\n                             \"mm_max_max_wind\")\n\nWe then add the min-max transformed columns to the main dataset.\n\ndengue_weather_wk_tf &lt;- dengue_weather_wk_tf %&gt;%\n  left_join(minmax_result, by = join_by(Year, WkNo))\n\nsummary(dengue_weather_wk_tf)\n\n      Year           WkNo           Cases         avg_daily_rainfall\n Min.   :2013   Min.   : 1.00   Min.   :  24.00   Min.   : 0.000    \n 1st Qu.:2015   1st Qu.:14.75   1st Qu.:  77.75   1st Qu.: 2.720    \n Median :2017   Median :27.00   Median : 229.50   Median : 5.148    \n Mean   :2017   Mean   :27.00   Mean   : 291.68   Mean   : 5.976    \n 3rd Qu.:2019   3rd Qu.:40.00   3rd Qu.: 378.50   3rd Qu.: 8.486    \n Max.   :2020   Max.   :52.00   Max.   :1792.00   Max.   :27.621    \n                                                                    \n tot_daily_rainfall max_highest_30m_rainfall max_highest_60m_rainfall\n Min.   :  0.00     Min.   : -Inf            Min.   :  -Inf          \n 1st Qu.: 19.04     1st Qu.:20.55            1st Qu.: 24.15          \n Median : 36.03     Median :32.40            Median : 41.60          \n Mean   : 41.91     Mean   : -Inf            Mean   :  -Inf          \n 3rd Qu.: 59.40     3rd Qu.:40.00            3rd Qu.: 55.85          \n Max.   :193.35     Max.   :65.20            Max.   :102.60          \n                                                                     \n max_highest_120m_rainfall avg_mean_temp    max_max_temp   min_min_temp  \n Min.   : -Inf             Min.   :24.56   Min.   :31.0   Min.   : 0.00  \n 1st Qu.: 26.2             1st Qu.:27.53   1st Qu.:34.1   1st Qu.:22.10  \n Median : 46.4             Median :28.09   Median :34.7   Median :22.60  \n Mean   : -Inf             Mean   :28.07   Mean   :34.6   Mean   :22.41  \n 3rd Qu.: 64.0             3rd Qu.:28.68   3rd Qu.:35.2   3rd Qu.:23.10  \n Max.   :122.8             Max.   :30.09   Max.   :37.5   Max.   :24.80  \n                                                                         \n avg_mean_wind     max_max_wind      log_cases     log_avg_daily_rainfall\n Min.   : 5.442   Min.   : 35.30   Min.   :3.219   Min.   :0.000         \n 1st Qu.: 7.070   1st Qu.: 55.40   1st Qu.:4.366   1st Qu.:1.314         \n Median : 8.057   Median : 63.40   Median :5.440   Median :1.816         \n Mean   : 8.348   Mean   : 66.63   Mean   :5.272   Mean   :1.713         \n 3rd Qu.: 9.255   3rd Qu.: 73.17   3rd Qu.:5.939   3rd Qu.:2.250         \n Max.   :14.846   Max.   :138.60   Max.   :7.492   Max.   :3.354         \n                                                                         \n log_tot_daily_rainfall log_max_highest_30m_rainfall\n Min.   :0.000          Min.   :0.000               \n 1st Qu.:2.998          1st Qu.:3.231               \n Median :3.612          Median :3.550               \n Mean   :3.373          Mean   :3.349               \n 3rd Qu.:4.101          3rd Qu.:3.731               \n Max.   :5.270          Max.   :4.193               \n                        NA's   :33                  \n log_max_highest_60m_rainfall log_max_highest_120m_rainfall log_avg_mean_temp\n Min.   :0.000                Min.   :0.000                 Min.   :3.241    \n 1st Qu.:3.466                1st Qu.:3.550                 1st Qu.:3.351    \n Median :3.798                Median :3.900                 Median :3.370    \n Mean   :3.589                Mean   :3.696                 Mean   :3.369    \n 3rd Qu.:4.057                3rd Qu.:4.190                 3rd Qu.:3.390    \n Max.   :4.641                Max.   :4.819                 Max.   :3.437    \n NA's   :33                   NA's   :33                                     \n log_max_max_temp log_min_min_temp log_avg_mean_wind log_max_max_wind\n Min.   :3.466    Min.   :0.000    Min.   :1.863     Min.   :3.592   \n 1st Qu.:3.558    1st Qu.:3.140    1st Qu.:2.088     1st Qu.:4.032   \n Median :3.575    Median :3.161    Median :2.204     Median :4.165   \n Mean   :3.572    Mean   :3.136    Mean   :2.219     Mean   :4.188   \n 3rd Qu.:3.589    3rd Qu.:3.182    3rd Qu.:2.328     3rd Qu.:4.306   \n Max.   :3.651    Max.   :3.250    Max.   :2.763     Max.   :4.939   \n                                                                     \n     z_cases.V1      z_avg_daily_rainfall.V1 z_tot_daily_rainfall.V1\n Min.   :-0.944070   Min.   :-1.356442       Min.   :-1.352349      \n 1st Qu.:-0.754502   1st Qu.:-0.739108       1st Qu.:-0.737984      \n Median :-0.219303   Median :-0.188006       Median :-0.189533      \n Mean   : 0.000000   Mean   : 0.000000       Mean   : 0.000000      \n 3rd Qu.: 0.306197   3rd Qu.: 0.569720       3rd Qu.: 0.564550      \n Max.   : 5.291392   Max.   : 4.913223       Max.   : 4.887166      \n                                                                    \n z_avg_mean_temp.V1   z_max_max_temp.V1   z_min_min_temp.V1  \n Min.   :-4.202192   Min.   :-4.057361   Min.   :-10.554820  \n 1st Qu.:-0.645443   1st Qu.:-0.559805   1st Qu.: -0.146930  \n Median : 0.021603   Median : 0.117142   Median :  0.088543  \n Mean   : 0.000000   Mean   : 0.000000   Mean   :  0.000000  \n 3rd Qu.: 0.719704   3rd Qu.: 0.681264   3rd Qu.:  0.324015  \n Max.   : 2.408351   Max.   : 3.276225   Max.   :  1.124622  \n                                                             \n z_avg_mean_wind.V1   z_max_max_wind.V1     mm_Cases      mm_avg_daily_rainfall\n Min.   :-1.664669   Min.   :-1.916568   Min.   :0.0000   Min.   :0.00000      \n 1st Qu.:-0.731889   1st Qu.:-0.687113   1st Qu.:0.0304   1st Qu.:0.09846      \n Median :-0.166464   Median :-0.197778   Median :0.1162   Median :0.18636      \n Mean   : 0.000000   Mean   : 0.000000   Mean   :0.1514   Mean   :0.21635      \n 3rd Qu.: 0.519948   3rd Qu.: 0.400128   3rd Qu.:0.2005   3rd Qu.:0.30722      \n Max.   : 3.722729   Max.   : 4.401973   Max.   :1.0000   Max.   :1.00000      \n                                                                               \n mm_tot_daily_rainfall mm_avg_mean_temp mm_max_max_temp  mm_min_min_temp \n Min.   :0.00000       Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.09846       1st Qu.:0.5380   1st Qu.:0.4769   1st Qu.:0.8911  \n Median :0.18636       Median :0.6389   Median :0.5692   Median :0.9113  \n Mean   :0.21674       Mean   :0.6357   Mean   :0.5533   Mean   :0.9037  \n 3rd Qu.:0.30722       3rd Qu.:0.7446   3rd Qu.:0.6462   3rd Qu.:0.9315  \n Max.   :1.00000       Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                                                         \n mm_avg_mean_wind mm_max_max_wind \n Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.1731   1st Qu.:0.1946  \n Median :0.2781   Median :0.2720  \n Mean   :0.3090   Mean   :0.3033  \n 3rd Qu.:0.4055   3rd Qu.:0.3667  \n Max.   :1.0000   Max.   :1.0000  \n                                  \n\n\nWe can save the data with transformation in csv file format for future reference.\n\nwrite.csv(dengue_weather_wk_tf, \"../../Data/dengue_climate_joined_by_week_transformed.csv\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#explanatory-model",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#explanatory-model",
    "title": "Prototyping Modules for Visual Analytics Shiny Application",
    "section": "3. Explanatory Model",
    "text": "3. Explanatory Model\n\n3.1 Linear Regression Model without Transformation\n\n# Fit linear regression model using all the data without normalization\n\nlm_nf_m1 &lt;- lm(Cases ~ avg_daily_rainfall + \n                  tot_daily_rainfall +\n                  avg_mean_temp + \n                  max_max_temp +\n                  min_min_temp +\n                  avg_mean_wind +\n                  max_max_wind, data = dengue_weather_wk_tf)\n\nsummary(lm_nf_m1)\n\n\nCall:\nlm(formula = Cases ~ avg_daily_rainfall + tot_daily_rainfall + \n    avg_mean_temp + max_max_temp + min_min_temp + avg_mean_wind + \n    max_max_wind, data = dengue_weather_wk_tf)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-388.19 -167.00  -52.92   85.50 1467.96 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        -903.0262   716.5219  -1.260  0.20833    \navg_daily_rainfall  114.3264    97.7320   1.170  0.24281    \ntot_daily_rainfall  -14.6723    13.8930  -1.056  0.29159    \navg_mean_temp       105.4545    23.8501   4.422 1.28e-05 ***\nmax_max_temp        -58.7096    20.0177  -2.933  0.00356 ** \nmin_min_temp          3.3374     6.7304   0.496  0.62027    \navg_mean_wind        18.8495     9.8953   1.905  0.05754 .  \nmax_max_wind         -0.5278     0.9016  -0.585  0.55857    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 277.4 on 384 degrees of freedom\nMultiple R-squared:  0.05986,   Adjusted R-squared:  0.04273 \nF-statistic: 3.493 on 7 and 384 DF,  p-value: 0.001207\n\n\nCheck the model statistics.\n\ncheck_model(lm_nf_m1)\n\n\n\n\nAverage daily rainfall and total rain fall are highly correlated. We shall retain the total rainfall variable.\n\nlm_nf_m2 &lt;- lm(Cases ~ tot_daily_rainfall +\n                  avg_mean_temp + \n                  max_max_temp +\n                  min_min_temp +\n                  avg_mean_wind +\n                  max_max_wind, data = dengue_weather_wk_tf)\n\n# Backward stepwise regression\nlm_nf_m2_bw &lt;- step(lm_nf_m2, direction = \"backward\")\n\nStart:  AIC=4417.72\nCases ~ tot_daily_rainfall + avg_mean_temp + max_max_temp + min_min_temp + \n    avg_mean_wind + max_max_wind\n\n                     Df Sum of Sq      RSS    AIC\n- min_min_temp        1     17505 29675338 4415.9\n- max_max_wind        1     22337 29680171 4416.0\n&lt;none&gt;                            29657834 4417.7\n- avg_mean_wind       1    269020 29926854 4419.3\n- tot_daily_rainfall  1    454962 30112795 4421.7\n- max_max_temp        1    629941 30287774 4424.0\n- avg_mean_temp       1   1495433 31153266 4435.0\n\nStep:  AIC=4415.95\nCases ~ tot_daily_rainfall + avg_mean_temp + max_max_temp + avg_mean_wind + \n    max_max_wind\n\n                     Df Sum of Sq      RSS    AIC\n- max_max_wind        1     25867 29701205 4414.3\n&lt;none&gt;                            29675338 4415.9\n- avg_mean_wind       1    283377 29958715 4417.7\n- tot_daily_rainfall  1    468397 30143735 4420.1\n- max_max_temp        1    624858 30300197 4422.1\n- avg_mean_temp       1   1557693 31233031 4434.0\n\nStep:  AIC=4414.29\nCases ~ tot_daily_rainfall + avg_mean_temp + max_max_temp + avg_mean_wind\n\n                     Df Sum of Sq      RSS    AIC\n&lt;none&gt;                            29701205 4414.3\n- avg_mean_wind       1    291241 29992446 4416.1\n- tot_daily_rainfall  1    442715 30143920 4418.1\n- max_max_temp        1    636912 30338118 4420.6\n- avg_mean_temp       1   1537560 31238765 4432.1\n\nsummary(lm_nf_m2_bw)\n\n\nCall:\nlm(formula = Cases ~ tot_daily_rainfall + avg_mean_temp + max_max_temp + \n    avg_mean_wind, data = dengue_weather_wk_tf)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-391.47 -172.34  -55.57   91.18 1478.24 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        -909.4370   712.9637  -1.276  0.20287    \ntot_daily_rainfall    1.5018     0.6253   2.402  0.01679 *  \navg_mean_temp       105.5657    23.5851   4.476    1e-05 ***\nmax_max_temp        -57.3853    19.9201  -2.881  0.00419 ** \navg_mean_wind        19.1489     9.8299   1.948  0.05213 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 277 on 387 degrees of freedom\nMultiple R-squared:  0.05513,   Adjusted R-squared:  0.04537 \nF-statistic: 5.646 on 4 and 387 DF,  p-value: 2e-04\n\n\nCheck the model statistics.\n\ncheck_model(lm_nf_m2_bw)\n\n\n\n\n\n\n3.2 Linear Regression with log transformation\n\n# Fit linear regression model using all the data with log transformation\n\nlm_log_m1 &lt;- lm(log_cases ~ log_tot_daily_rainfall +\n                  log_avg_mean_temp + \n                  log_max_max_temp +\n                  log_min_min_temp +\n                  log_avg_mean_wind +\n                  log_max_max_wind, data = dengue_weather_wk_tf)\n\nsummary(lm_log_m1)\n\n\nCall:\nlm(formula = log_cases ~ log_tot_daily_rainfall + log_avg_mean_temp + \n    log_max_max_temp + log_min_min_temp + log_avg_mean_wind + \n    log_max_max_wind, data = dengue_weather_wk_tf)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.8972 -0.7954  0.1677  0.6609  2.2296 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            -9.07402    7.55032  -1.202 0.230177    \nlog_tot_daily_rainfall  0.05977    0.06011   0.994 0.320719    \nlog_avg_mean_temp       7.51679    2.14357   3.507 0.000507 ***\nlog_max_max_temp       -3.59951    2.38016  -1.512 0.131279    \nlog_min_min_temp        0.12649    0.16997   0.744 0.457195    \nlog_avg_mean_wind       0.54012    0.33561   1.609 0.108353    \nlog_max_max_wind        0.01888    0.22657   0.083 0.933631    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9298 on 385 degrees of freedom\nMultiple R-squared:  0.04077,   Adjusted R-squared:  0.02582 \nF-statistic: 2.727 on 6 and 385 DF,  p-value: 0.01318\n\n\nBackward stepwise regression.\n\nlm_log_m1_bw &lt;- step(lm_log_m1, direction = \"backward\")\n\nStart:  AIC=-50.11\nlog_cases ~ log_tot_daily_rainfall + log_avg_mean_temp + log_max_max_temp + \n    log_min_min_temp + log_avg_mean_wind + log_max_max_wind\n\n                         Df Sum of Sq    RSS     AIC\n- log_max_max_wind        1    0.0060 332.86 -52.102\n- log_min_min_temp        1    0.4789 333.34 -51.546\n- log_tot_daily_rainfall  1    0.8547 333.71 -51.104\n&lt;none&gt;                                332.86 -50.110\n- log_max_max_temp        1    1.9773 334.84 -49.788\n- log_avg_mean_wind       1    2.2393 335.10 -49.481\n- log_avg_mean_temp       1   10.6314 343.49 -39.785\n\nStep:  AIC=-52.1\nlog_cases ~ log_tot_daily_rainfall + log_avg_mean_temp + log_max_max_temp + \n    log_min_min_temp + log_avg_mean_wind\n\n                         Df Sum of Sq    RSS     AIC\n- log_min_min_temp        1    0.4747 333.34 -53.544\n- log_tot_daily_rainfall  1    0.9710 333.84 -52.961\n&lt;none&gt;                                332.86 -52.102\n- log_max_max_temp        1    1.9737 334.84 -51.785\n- log_avg_mean_wind       1    2.2422 335.11 -51.471\n- log_avg_mean_temp       1   10.6954 343.56 -41.705\n\nStep:  AIC=-53.54\nlog_cases ~ log_tot_daily_rainfall + log_avg_mean_temp + log_max_max_temp + \n    log_avg_mean_wind\n\n                         Df Sum of Sq    RSS     AIC\n- log_tot_daily_rainfall  1    0.9901 334.33 -54.381\n&lt;none&gt;                                333.34 -53.544\n- log_max_max_temp        1    1.9289 335.27 -53.282\n- log_avg_mean_wind       1    2.3541 335.69 -52.785\n- log_avg_mean_temp       1   10.8233 344.16 -43.018\n\nStep:  AIC=-54.38\nlog_cases ~ log_avg_mean_temp + log_max_max_temp + log_avg_mean_wind\n\n                    Df Sum of Sq    RSS     AIC\n- log_avg_mean_wind  1    1.3744 335.70 -54.773\n&lt;none&gt;                           334.33 -54.381\n- log_max_max_temp   1    1.8541 336.18 -54.213\n- log_avg_mean_temp  1    9.8333 344.16 -45.018\n\nStep:  AIC=-54.77\nlog_cases ~ log_avg_mean_temp + log_max_max_temp\n\n                    Df Sum of Sq    RSS     AIC\n&lt;none&gt;                           335.70 -54.773\n- log_max_max_temp   1    2.6617 338.37 -53.677\n- log_avg_mean_temp  1   11.1170 346.82 -44.002\n\nsummary(lm_log_m1_bw)\n\n\nCall:\nlm(formula = log_cases ~ log_avg_mean_temp + log_max_max_temp, \n    data = dengue_weather_wk_tf)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.8753 -0.7805  0.1471  0.6921  2.2518 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         -4.493      6.943  -0.647 0.517920    \nlog_avg_mean_temp    7.231      2.015   3.589 0.000374 ***\nlog_max_max_temp    -4.087      2.327  -1.756 0.079842 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.929 on 389 degrees of freedom\nMultiple R-squared:  0.03257,   Adjusted R-squared:  0.0276 \nF-statistic: 6.549 on 2 and 389 DF,  p-value: 0.001595\n\n\nCheck the model statistics.\n\ncheck_model(lm_log_m1_bw)\n\n\n\n\n\n\n3.3 Linear Regression with standardization transformation\n\n# Fit linear regression model using all the data with standardization transformation\n\nlm_z_m1 &lt;- lm(z_cases ~ z_tot_daily_rainfall +\n                  z_avg_mean_temp + \n                  z_max_max_temp +\n                  z_min_min_temp +\n                  z_avg_mean_wind +\n                  z_max_max_wind, data = dengue_weather_wk_tf)\n\nsummary(lm_z_m1)\n\n\nCall:\nlm(formula = z_cases ~ z_tot_daily_rainfall + z_avg_mean_temp + \n    z_max_max_temp + z_min_min_temp + z_avg_mean_wind + z_max_max_wind, \n    data = dengue_weather_wk_tf)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.3696 -0.5930 -0.1819  0.3062  5.1818 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          -4.275e-16  4.944e-02   0.000  1.00000    \nz_tot_daily_rainfall  1.707e-01  7.025e-02   2.430  0.01555 *  \nz_avg_mean_temp       3.102e-01  7.040e-02   4.406 1.37e-05 ***\nz_max_max_temp       -1.786e-01  6.246e-02  -2.860  0.00447 ** \nz_min_min_temp        2.404e-02  5.042e-02   0.477  0.63385    \nz_avg_mean_wind       1.138e-01  6.092e-02   1.869  0.06242 .  \nz_max_max_wind       -2.798e-02  5.197e-02  -0.538  0.59055    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9789 on 385 degrees of freedom\nMultiple R-squared:  0.05651,   Adjusted R-squared:  0.04181 \nF-statistic: 3.844 on 6 and 385 DF,  p-value: 0.0009773\n\n\nBackward stepwise regression.\n\nlm_z_m1_bw &lt;- step(lm_z_m1, direction = \"backward\")\n\nStart:  AIC=-9.81\nz_cases ~ z_tot_daily_rainfall + z_avg_mean_temp + z_max_max_temp + \n    z_min_min_temp + z_avg_mean_wind + z_max_max_wind\n\n                       Df Sum of Sq    RSS      AIC\n- z_min_min_temp        1    0.2177 369.12 -11.5741\n- z_max_max_wind        1    0.2778 369.18 -11.5103\n&lt;none&gt;                              368.90  -9.8054\n- z_avg_mean_wind       1    3.3462 372.25  -8.2657\n- z_tot_daily_rainfall  1    5.6591 374.56  -5.8377\n- z_max_max_temp        1    7.8356 376.74  -3.5664\n- z_avg_mean_temp       1   18.6011 387.50   7.4782\n\nStep:  AIC=-11.57\nz_cases ~ z_tot_daily_rainfall + z_avg_mean_temp + z_max_max_temp + \n    z_avg_mean_wind + z_max_max_wind\n\n                       Df Sum of Sq    RSS      AIC\n- z_max_max_wind        1    0.3217 369.44 -13.2326\n&lt;none&gt;                              369.12 -11.5741\n- z_avg_mean_wind       1    3.5248 372.65  -9.8486\n- z_tot_daily_rainfall  1    5.8262 374.95  -7.4351\n- z_max_max_temp        1    7.7724 376.89  -5.4057\n- z_avg_mean_temp       1   19.3756 388.50   6.4805\n\nStep:  AIC=-13.23\nz_cases ~ z_tot_daily_rainfall + z_avg_mean_temp + z_max_max_temp + \n    z_avg_mean_wind\n\n                       Df Sum of Sq    RSS      AIC\n&lt;none&gt;                              369.44 -13.2326\n- z_avg_mean_wind       1    3.6226 373.07 -11.4075\n- z_tot_daily_rainfall  1    5.5068 374.95  -9.4327\n- z_max_max_temp        1    7.9223 377.36  -6.9154\n- z_avg_mean_temp       1   19.1252 388.57   4.5525\n\nsummary(lm_z_m1_bw)\n\n\nCall:\nlm(formula = z_cases ~ z_tot_daily_rainfall + z_avg_mean_temp + \n    z_max_max_temp + z_avg_mean_wind, data = dengue_weather_wk_tf)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.3807 -0.6078 -0.1960  0.3216  5.2135 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          -4.221e-16  4.935e-02   0.000  1.00000    \nz_tot_daily_rainfall  1.641e-01  6.833e-02   2.402  0.01679 *  \nz_avg_mean_temp       3.115e-01  6.959e-02   4.476    1e-05 ***\nz_max_max_temp       -1.794e-01  6.227e-02  -2.881  0.00419 ** \nz_avg_mean_wind       1.179e-01  6.052e-02   1.948  0.05213 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9771 on 387 degrees of freedom\nMultiple R-squared:  0.05513,   Adjusted R-squared:  0.04537 \nF-statistic: 5.646 on 4 and 387 DF,  p-value: 2e-04\n\n\nCheck the model statistics.\n\ncheck_model(lm_z_m1_bw)\n\n\n\n\n\n\n3.3 Linear Regression with min-max transformation\n\n# Fit linear regression model using all the data with min-max transformation\n\nlm_mm_m1 &lt;- lm(mm_Cases ~ mm_tot_daily_rainfall +\n                  mm_avg_mean_temp + \n                  mm_max_max_temp +\n                  mm_min_min_temp +\n                  mm_avg_mean_wind +\n                  mm_max_max_wind, data = dengue_weather_wk_tf)\n\nsummary(lm_mm_m1)\n\n\nCall:\nlm(formula = mm_Cases ~ mm_tot_daily_rainfall + mm_avg_mean_temp + \n    mm_max_max_temp + mm_min_min_temp + mm_avg_mean_wind + mm_max_max_wind, \n    data = dengue_weather_wk_tf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.21964 -0.09510 -0.02916  0.04911  0.83103 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           -0.04090    0.09971  -0.410  0.68190    \nmm_tot_daily_rainfall  0.17085    0.07030   2.430  0.01555 *  \nmm_avg_mean_temp       0.32882    0.07463   4.406 1.37e-05 ***\nmm_max_max_temp       -0.21008    0.07346  -2.860  0.00447 ** \nmm_min_min_temp        0.04502    0.09444   0.477  0.63385    \nmm_avg_mean_wind       0.09836    0.05263   1.869  0.06242 .  \nmm_max_max_wind       -0.02836    0.05266  -0.538  0.59055    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.157 on 385 degrees of freedom\nMultiple R-squared:  0.05651,   Adjusted R-squared:  0.04181 \nF-statistic: 3.844 on 6 and 385 DF,  p-value: 0.0009773\n\n\nBackward stepwise regression.\n\nlm_mm_m1_bw &lt;- step(lm_mm_m1, direction = \"backward\")\n\nStart:  AIC=-1444.72\nmm_Cases ~ mm_tot_daily_rainfall + mm_avg_mean_temp + mm_max_max_temp + \n    mm_min_min_temp + mm_avg_mean_wind + mm_max_max_wind\n\n                        Df Sum of Sq    RSS     AIC\n- mm_min_min_temp        1   0.00560 9.4936 -1446.5\n- mm_max_max_wind        1   0.00715 9.4952 -1446.4\n&lt;none&gt;                               9.4880 -1444.7\n- mm_avg_mean_wind       1   0.08606 9.5741 -1443.2\n- mm_tot_daily_rainfall  1   0.14555 9.6336 -1440.8\n- mm_max_max_temp        1   0.20153 9.6895 -1438.5\n- mm_avg_mean_temp       1   0.47841 9.9664 -1427.4\n\nStep:  AIC=-1446.49\nmm_Cases ~ mm_tot_daily_rainfall + mm_avg_mean_temp + mm_max_max_temp + \n    mm_avg_mean_wind + mm_max_max_wind\n\n                        Df Sum of Sq    RSS     AIC\n- mm_max_max_wind        1   0.00828 9.5019 -1448.2\n&lt;none&gt;                               9.4936 -1446.5\n- mm_avg_mean_wind       1   0.09066 9.5843 -1444.8\n- mm_tot_daily_rainfall  1   0.14985 9.6435 -1442.3\n- mm_max_max_temp        1   0.19990 9.6935 -1440.3\n- mm_avg_mean_temp       1   0.49833 9.9919 -1428.4\n\nStep:  AIC=-1448.15\nmm_Cases ~ mm_tot_daily_rainfall + mm_avg_mean_temp + mm_max_max_temp + \n    mm_avg_mean_wind\n\n                        Df Sum of Sq    RSS     AIC\n&lt;none&gt;                               9.5019 -1448.2\n- mm_avg_mean_wind       1   0.09317 9.5951 -1446.3\n- mm_tot_daily_rainfall  1   0.14163 9.6435 -1444.3\n- mm_max_max_temp        1   0.20376 9.7056 -1441.8\n- mm_avg_mean_temp       1   0.49189 9.9938 -1430.4\n\nsummary(lm_mm_m1_bw)\n\n\nCall:\nlm(formula = mm_Cases ~ mm_tot_daily_rainfall + mm_avg_mean_temp + \n    mm_max_max_temp + mm_avg_mean_wind, data = dengue_weather_wk_tf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.22142 -0.09748 -0.03143  0.05157  0.83611 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           -0.008838   0.062128  -0.142  0.88695    \nmm_tot_daily_rainfall  0.164229   0.068378   2.402  0.01679 *  \nmm_avg_mean_temp       0.330195   0.073771   4.476    1e-05 ***\nmm_max_max_temp       -0.210975   0.073236  -2.881  0.00419 ** \nmm_avg_mean_wind       0.101853   0.052285   1.948  0.05213 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1567 on 387 degrees of freedom\nMultiple R-squared:  0.05513,   Adjusted R-squared:  0.04537 \nF-statistic: 5.646 on 4 and 387 DF,  p-value: 2e-04\n\n\nCheck the model statistics.\n\ncheck_model(lm_mm_m1_bw)\n\n\n\n\n\n\n3.4 Compare Multiple Models\n\ncompare_performance(lm_nf_m2_bw, lm_log_m1_bw, lm_z_m1_bw, lm_mm_m1_bw, rank = TRUE)\n\n# Comparison of Model Performance Indices\n\nName         | Model |    R2 | R2 (adj.) |    RMSE |   Sigma | AIC weights | AICc weights | BIC weights | Performance-Score\n---------------------------------------------------------------------------------------------------------------------------\nlm_mm_m1_bw  |    lm | 0.055 |     0.045 |   0.156 |   0.157 |        1.00 |         1.00 |        1.00 |           100.00%\nlm_z_m1_bw   |    lm | 0.055 |     0.045 |   0.971 |   0.977 |   2.58e-312 |    2.58e-312 |   2.58e-312 |            57.06%\nlm_nf_m2_bw  |    lm | 0.055 |     0.045 | 275.261 | 277.033 |    0.00e+00 |     0.00e+00 |    0.00e+00 |            28.57%\nlm_log_m1_bw |    lm | 0.033 |     0.028 |   0.925 |   0.929 |   2.70e-303 |    2.86e-303 |   1.43e-301 |            28.49%\n\n\nFrom the comparison table above, the linear regression model with min-max transformation has the highest R^2. Therefore, this model would be chosen as the best model among the four models calibrated.\nLet’s visualize the coefficients.\n\nggcoefstats(lm_mm_m1_bw, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to visualize time oriented data in R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "title": "Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to visualize time oriented data in R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Visualising and Analysing Time-oriented Data",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required libraries\nFirstly, let’s install and load the required packages:\n\ntidyverse: an opinionated collection of R packages designed for data import, data wrangling and data exploration\nscales: provides the internal scaling infrastructure used by ggplot2, and provides tools to override the default breaks, labels, transformations and palettes.\nviridis: provide a series of color maps that are designed to improve graph readability for readers with common forms of color blindness and/or color vision deficiency.\nlubridate: makes it easier to handle date and time data in R\nggthemes: provides ‘ggplot2’ themes.\ngridExtra: provides a number of user-level functions to work with “grid” graphics, notably to arrange multiple grid-based plots on a page, and draw tables.\nreadxl: makes it easy to get data out of Excel and into R.\nknitr: provides a general-purpose tool for dynamic report generation in R using Literate Programming techniques.\ndata.table: makes it faster to aggregate and modify large data.\nCGPfunctions: miscellaneous functions useful for teaching statistics as well as actually practicing the art.\nggHoriPlot: makes it easy to build horizon plots in ggplot2.\n\n\npacman::p_load(tidyverse, scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot)\n\n\n\n2.2 Importing the data\nIn this exercise, eventlog.csv file will be used. This data file contains 199,999 records of cyber attacks arranged by time and by country.\nLet’s start by importing the data.\n\nattacks &lt;- read_csv(\"../../Data/eventlog.csv\")\n\nRows: 199999 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): source_country, tz\ndttm (1): timestamp\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n2.3 Examing the data structure\nIn this section, we’ll use kable() to review the structure of the data.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere data frame contains three columns:\n\ntimestamp: stores date-time values in POSIXct format.\nsource_country: stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz: stores time zone of the source IP address.\n\n\n\n2.4 Preparing the data\nStep 1: Deriving two new columns from the timestamp variable\n\nwkday: the day of the week when the attack happend\nhour: the hour when the attack happened\n\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nCheck the resulting data frame.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-the-calendar-heatmaps",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-the-calendar-heatmaps",
    "title": "Visualising and Analysing Time-oriented Data",
    "section": "3. Building the Calendar Heatmaps",
    "text": "3. Building the Calendar Heatmaps\n\n3.1 Single calendar heatmaps\nWe use the code chunk below to build the calendar hearmap.\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\n\n\n\n\n\n3.2 Multiple calendar heatmaps\nIn the previous section, we made a heatmap to review the patterns of the attacks for the entire data frame.\nWe can also plot the heatmaps by country to reveal the patterns within the countries.\nStep 1: Deriving attack by country object\nWe first calculate the percentage of attacks by country.\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nWe’ll plot the heatmaps for four countries with the most attacks. Hence, let’s create a subset of the main data frame that only contains the records from top 4 countries.\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\n\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "title": "Visualising and Analysing Time-oriented Data",
    "section": "4. Plotting Cycle Plot",
    "text": "4. Plotting Cycle Plot\nIn this section, we will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n4.1 Importing the data\nWe’ll use arrivals_by_air.xlsx file for this section.\nLet’s first import the data.\n\nair &lt;- read_excel(\"../../Data/arrivals_by_air.xlsx\")\n\nThe data file contains 240 rows and 36 columns\n\n\n4.2 Preparing the data\nSince we are going to plot the cycle graph by month and by year, we’ll need to create these two columns from Month-Year column.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels = 1:12, \n                    labels = month.abb, \n                    ordered = TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\nNext we’ll filter the dataset by country = Vietnam, for example.\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\nWe use the code chunk below to compute the year average arrivals by month which serves as a reference line in the cycle plot later.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\nPlotting cycle plot\nWe are now ready to make the plot.\n\nggplot() + \n  geom_line(data = Vietnam,\n            aes(x = year, \n                y = `Vietnam`, \n                group = month), \n            colour = \"black\") +\n  geom_hline(aes(yintercept = avgvalue), \n             data = hline.data, \n             linetype = 6, \n             colour = \"red\", \n             size = 0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "title": "Visualising and Analysing Time-oriented Data",
    "section": "5. Plotting Slopegraph",
    "text": "5. Plotting Slopegraph\nIn this section we will learn how to plot a slopegraph using R.\n\n5.1 Installing R packages\nFirstly, we need to load a new package called CGPfunctions into R.\n\npacman::p_load(CGPfunctions)\n\n\n\n5.2 Importing the data\nWe’ll use rice.csv file in this section.\n\nrice &lt;- read_csv(\"../../Data/rice.csv\")\n\nRows: 550 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Country\ndbl (3): Year, Yield, Production\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe data set contains 550 rows and 4 columns.\n\n\n5.3 Plotting the slopegraph\nNext, let’s make the plot.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Originally prepared by: Dr. Kam Tin Seong\")\n\n\nConverting 'Year' to an ordered factor\n\n\n\n\n\nThis comes to the end of this hands-on exercise. I have learned to make static and interactive treemaps plots in R. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04_2014_ts-regression.html",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04_2014_ts-regression.html",
    "title": "Take-home_Ex04_ts-regression",
    "section": "",
    "text": "pacman::p_load(tidyverse, tsibbledata, fable, feasts, tsibble, ggstatsplot, performance)\n\n\ndengue_weather_wk_2014_tf &lt;- read_csv(\"../../Data/dengue_climate_joined_by_week_2014_transformed.csv\")\n\nNew names:\nRows: 359 Columns: 47\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" dbl\n(47): ...1, Year, WkNo, Cases, avg_daily_rainfall, tot_daily_rainfall, m...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n\nThe dataframe needs to be converted to a tsibble object before running TSLM model.\n\n# Create a date column which will be used to convert to a yearweek object in the next step\n\ndengue_weather_wk_2014_tf &lt;- dengue_weather_wk_2014_tf %&gt;%\n  mutate('Date' = make_date(year = Year) + weeks(WkNo))\n\n\n# Convert the tibble dataframe to a tsibble dataframe\n\ndengue_weather_tsreg &lt;- dengue_weather_wk_2014_tf %&gt;%\n  mutate(Week = yearweek(Date)) %&gt;%\n  as_tsibble(index = Week) %&gt;%\n  fill_gaps(.full = TRUE)\n\n\nts_log_m1 &lt;- dengue_weather_tsreg %&gt;%\n  model(TSLM(log_cases ~ log_tot_daily_rainfall + \n                  log_tot_daily_rainfall +\n                  log_avg_mean_temp + \n                  log_max_max_temp +\n                  log_min_min_temp +\n                  log_avg_mean_wind +\n                  log_max_max_wind))\n\nreport(ts_log_m1)\n\nSeries: log_cases \nModel: TSLM \n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9871 -0.7656  0.1410  0.6143  2.3336 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            -16.3601     7.7405  -2.114 0.035255 *  \nlog_tot_daily_rainfall   0.1142     0.0613   1.863 0.063264 .  \nlog_avg_mean_temp        8.8488     2.1713   4.075 5.68e-05 ***\nlog_max_max_temp        -3.4219     2.4024  -1.424 0.155234    \nlog_min_min_temp         0.1040     0.1669   0.623 0.533909    \nlog_avg_mean_wind        1.2547     0.3505   3.580 0.000392 ***\nlog_max_max_wind         0.1070     0.2291   0.467 0.640803    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9124 on 352 degrees of freedom\nMultiple R-squared: 0.07932,    Adjusted R-squared: 0.06363\nF-statistic: 5.054 on 6 and 352 DF, p-value: 5.4448e-05\n\n\n\ngg_tsresiduals(ts_log_m1)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\naugment(ts_log_m1) %&gt;%\n  ggplot(aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  labs(title = \"Relationship between residuals and fitted values.\",\n       subtitle = \"if a relationship exists, then response variable may require transformation.\",\n       y = \"Residuals\", x = \"Fitted\") +\n  theme_light()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\nggcoefstats(ts_log_m1 %&gt;% tidy(), \n            output = \"plot\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04_2014.html",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04_2014.html",
    "title": "Project Data subset 2014 onwards",
    "section": "",
    "text": "pacman::p_load(tidyverse, lubridate, caret, performance, ggstatsplot, forecast)\n\n\ndengue_weather_wk &lt;- read_csv(\"D:/MITB_SunYP/ISSS608/Data/dengue_climate_joined_by_week.csv\")\n\nRows: 392 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (13): Year, WkNo, Cases, avg_daily_rainfall, tot_daily_rainfall, max_hig...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ndengue_weather_wk_2014 &lt;- subset(dengue_weather_wk, Year &gt;= 2014)\n\nsummary(dengue_weather_wk_2014)\n\n      Year           WkNo           Cases        avg_daily_rainfall\n Min.   :2014   Min.   : 1.00   Min.   :  24.0   Min.   : 0.000    \n 1st Qu.:2015   1st Qu.:13.00   1st Qu.:  75.0   1st Qu.: 2.689    \n Median :2017   Median :26.00   Median : 216.0   Median : 5.071    \n Mean   :2017   Mean   :26.17   Mean   : 274.9   Mean   : 5.862    \n 3rd Qu.:2019   3rd Qu.:39.00   3rd Qu.: 361.5   3rd Qu.: 8.412    \n Max.   :2020   Max.   :52.00   Max.   :1792.0   Max.   :27.621    \n tot_daily_rainfall max_highest_30m_rainfall max_highest_60m_rainfall\n Min.   :  0.00     Min.   : 0.00            Min.   :  0.00          \n 1st Qu.: 18.82     1st Qu.:24.30            1st Qu.: 31.00          \n Median : 35.50     Median :33.80            Median : 43.60          \n Mean   : 41.12     Mean   :32.27            Mean   : 42.76          \n 3rd Qu.: 58.88     3rd Qu.:40.70            3rd Qu.: 56.80          \n Max.   :193.35     Max.   :65.20            Max.   :102.60          \n max_highest_120m_rainfall avg_mean_temp    max_max_temp    min_min_temp  \n Min.   :  0.00            Min.   :24.56   Min.   :31.00   Min.   : 0.00  \n 1st Qu.: 33.80            1st Qu.:27.58   1st Qu.:34.10   1st Qu.:22.10  \n Median : 48.40            Median :28.11   Median :34.70   Median :22.60  \n Mean   : 48.63            Mean   :28.10   Mean   :34.61   Mean   :22.44  \n 3rd Qu.: 65.00            3rd Qu.:28.70   3rd Qu.:35.20   3rd Qu.:23.15  \n Max.   :122.80            Max.   :29.99   Max.   :37.50   Max.   :24.80  \n avg_mean_wind     max_max_wind   \n Min.   : 5.631   Min.   : 35.30  \n 1st Qu.: 7.206   1st Qu.: 55.40  \n Median : 8.162   Median : 63.70  \n Mean   : 8.465   Mean   : 66.90  \n 3rd Qu.: 9.342   3rd Qu.: 73.25  \n Max.   :14.846   Max.   :138.60  \n\n\n\ndengue_weather_wk_2014_tf &lt;- dengue_weather_wk_2014 %&gt;%\n  mutate(log_cases = log1p(Cases),\n         log_avg_daily_rainfall = log1p(avg_daily_rainfall),\n         log_tot_daily_rainfall = log1p(tot_daily_rainfall),\n         log_max_highest_30m_rainfall = log1p(max_highest_30m_rainfall),\n         log_max_highest_60m_rainfall = log1p(max_highest_60m_rainfall),\n         log_max_highest_120m_rainfall = log1p(max_highest_120m_rainfall),\n         log_avg_mean_temp = log1p(avg_mean_temp),\n         log_max_max_temp = log1p(max_max_temp),\n         log_min_min_temp = log1p(min_min_temp),\n         log_avg_mean_wind = log1p(avg_mean_wind),\n         log_max_max_wind = log1p(max_max_wind),\n         z_cases = scale(Cases),\n         z_avg_daily_rainfall = scale(avg_daily_rainfall),\n         z_tot_daily_rainfall = scale(tot_daily_rainfall),\n         z_max_highest_30m_rainfall = scale(max_highest_30m_rainfall),\n         z_max_highest_60m_rainfall = scale(max_highest_60m_rainfall),\n         z_max_highest_120m_rainfall = scale(max_highest_120m_rainfall),\n         z_avg_mean_temp = scale(avg_mean_temp),\n         z_max_max_temp = scale(max_max_temp),\n         z_min_min_temp = scale(min_min_temp),\n         z_avg_mean_wind = scale(avg_mean_wind),\n         z_max_max_wind = scale(max_max_wind))\n\n\nminmax_preprocess &lt;- preProcess(dengue_weather_wk_2014, method = list(range = names(dengue_weather_wk_2014)[3:13]))\n\nminmax_result &lt;- predict(minmax_preprocess, dengue_weather_wk_2014)\n\ncolnames(minmax_result) &lt;- c(\"Year\",\n                             \"WkNo\",\n                             \"mm_Cases\",\n                             \"mm_avg_daily_rainfall\",\n                             \"mm_tot_daily_rainfall\",\n                             \"mm_max_highest_30m_rainfall\",\n                             \"mm_max_highest_60m_rainfall\",\n                             \"mm_max_highest_120m_rainfall\",\n                             \"mm_avg_mean_temp\",\n                             \"mm_max_max_temp\",\n                             \"mm_min_min_temp\",\n                             \"mm_avg_mean_wind\",\n                             \"mm_max_max_wind\")\n\ndengue_weather_wk_2014_tf &lt;- dengue_weather_wk_2014_tf %&gt;%\n  left_join(minmax_result, by = join_by(Year, WkNo))\n\nsummary(dengue_weather_wk_2014_tf)\n\n      Year           WkNo           Cases        avg_daily_rainfall\n Min.   :2014   Min.   : 1.00   Min.   :  24.0   Min.   : 0.000    \n 1st Qu.:2015   1st Qu.:13.00   1st Qu.:  75.0   1st Qu.: 2.689    \n Median :2017   Median :26.00   Median : 216.0   Median : 5.071    \n Mean   :2017   Mean   :26.17   Mean   : 274.9   Mean   : 5.862    \n 3rd Qu.:2019   3rd Qu.:39.00   3rd Qu.: 361.5   3rd Qu.: 8.412    \n Max.   :2020   Max.   :52.00   Max.   :1792.0   Max.   :27.621    \n tot_daily_rainfall max_highest_30m_rainfall max_highest_60m_rainfall\n Min.   :  0.00     Min.   : 0.00            Min.   :  0.00          \n 1st Qu.: 18.82     1st Qu.:24.30            1st Qu.: 31.00          \n Median : 35.50     Median :33.80            Median : 43.60          \n Mean   : 41.12     Mean   :32.27            Mean   : 42.76          \n 3rd Qu.: 58.88     3rd Qu.:40.70            3rd Qu.: 56.80          \n Max.   :193.35     Max.   :65.20            Max.   :102.60          \n max_highest_120m_rainfall avg_mean_temp    max_max_temp    min_min_temp  \n Min.   :  0.00            Min.   :24.56   Min.   :31.00   Min.   : 0.00  \n 1st Qu.: 33.80            1st Qu.:27.58   1st Qu.:34.10   1st Qu.:22.10  \n Median : 48.40            Median :28.11   Median :34.70   Median :22.60  \n Mean   : 48.63            Mean   :28.10   Mean   :34.61   Mean   :22.44  \n 3rd Qu.: 65.00            3rd Qu.:28.70   3rd Qu.:35.20   3rd Qu.:23.15  \n Max.   :122.80            Max.   :29.99   Max.   :37.50   Max.   :24.80  \n avg_mean_wind     max_max_wind      log_cases     log_avg_daily_rainfall\n Min.   : 5.631   Min.   : 35.30   Min.   :3.219   Min.   :0.000         \n 1st Qu.: 7.206   1st Qu.: 55.40   1st Qu.:4.331   1st Qu.:1.305         \n Median : 8.162   Median : 63.70   Median :5.380   Median :1.804         \n Mean   : 8.465   Mean   : 66.90   Mean   :5.195   Mean   :1.697         \n 3rd Qu.: 9.342   3rd Qu.: 73.25   3rd Qu.:5.893   3rd Qu.:2.242         \n Max.   :14.846   Max.   :138.60   Max.   :7.492   Max.   :3.354         \n log_tot_daily_rainfall log_max_highest_30m_rainfall\n Min.   :0.000          Min.   :0.000               \n 1st Qu.:2.987          1st Qu.:3.231               \n Median :3.597          Median :3.550               \n Mean   :3.351          Mean   :3.349               \n 3rd Qu.:4.092          3rd Qu.:3.730               \n Max.   :5.270          Max.   :4.193               \n log_max_highest_60m_rainfall log_max_highest_120m_rainfall log_avg_mean_temp\n Min.   :0.000                Min.   :0.000                 Min.   :3.241    \n 1st Qu.:3.466                1st Qu.:3.550                 1st Qu.:3.353    \n Median :3.798                Median :3.900                 Median :3.371    \n Mean   :3.589                Mean   :3.696                 Mean   :3.370    \n 3rd Qu.:4.057                3rd Qu.:4.190                 3rd Qu.:3.391    \n Max.   :4.641                Max.   :4.819                 Max.   :3.434    \n log_max_max_temp log_min_min_temp log_avg_mean_wind log_max_max_wind\n Min.   :3.466    Min.   :0.000    Min.   :1.892     Min.   :3.592   \n 1st Qu.:3.558    1st Qu.:3.140    1st Qu.:2.105     1st Qu.:4.032   \n Median :3.575    Median :3.161    Median :2.215     Median :4.170   \n Mean   :3.572    Mean   :3.136    Mean   :2.232     Mean   :4.192   \n 3rd Qu.:3.589    3rd Qu.:3.184    3rd Qu.:2.336     3rd Qu.:4.307   \n Max.   :3.651    Max.   :3.250    Max.   :2.763     Max.   :4.939   \n     z_cases.V1      z_avg_daily_rainfall.V1 z_tot_daily_rainfall.V1\n Min.   :-0.876938   Min.   :-1.349189       Min.   :-1.344507      \n 1st Qu.:-0.698651   1st Qu.:-0.730359       1st Qu.:-0.729058      \n Median :-0.205738   Median :-0.182033       Median :-0.183727      \n Mean   : 0.000000   Mean   : 0.000000       Mean   : 0.000000      \n 3rd Qu.: 0.302906   3rd Qu.: 0.586745       3rd Qu.: 0.580850      \n Max.   : 5.303697   Max.   : 5.007556       Max.   : 4.977509      \n z_max_highest_30m_rainfall.V1 z_max_highest_60m_rainfall.V1\n Min.   :-2.3955840            Min.   :-2.1740592           \n 1st Qu.:-0.5915911            1st Qu.:-0.5977487           \n Median : 0.1136737            Median : 0.0429452           \n Mean   : 0.0000000            Mean   : 0.0000000           \n 3rd Qu.: 0.6259186            3rd Qu.: 0.7141484           \n Max.   : 2.4447592            Max.   : 3.0430199           \n z_max_highest_120m_rainfall.V1 z_avg_mean_temp.V1   z_max_max_temp.V1 \n Min.   :-2.0470092             Min.   :-4.269985   Min.   :-4.057844  \n 1st Qu.:-0.6242987             1st Qu.:-0.619168   1st Qu.:-0.575982  \n Median :-0.0097550             Median : 0.018426   Median : 0.097926  \n Mean   : 0.0000000             Mean   : 0.000000   Mean   : 0.000000  \n 3rd Qu.: 0.6889726             3rd Qu.: 0.730885   3rd Qu.: 0.659517  \n Max.   : 3.1218919             Max.   : 2.281542   Max.   : 3.242834  \n  z_min_min_temp.V1   z_avg_mean_wind.V1   z_max_max_wind.V1     mm_Cases      \n Min.   :-10.193471   Min.   :-1.616940   Min.   :-1.893830   Min.   :0.00000  \n 1st Qu.: -0.156490   1st Qu.:-0.718670   1st Qu.:-0.689051   1st Qu.:0.02885  \n Median :  0.070591   Median :-0.173049   Median :-0.191555   Median :0.10860  \n Mean   :  0.000000   Mean   : 0.000000   Mean   : 0.000000   Mean   :0.14188  \n 3rd Qu.:  0.320380   3rd Qu.: 0.500423   3rd Qu.: 0.380865   3rd Qu.:0.19089  \n Max.   :  1.069748   Max.   : 3.640409   Max.   : 4.297895   Max.   :1.00000  \n mm_avg_daily_rainfall mm_tot_daily_rainfall mm_max_highest_30m_rainfall\n Min.   :0.00000       Min.   :0.00000       Min.   :0.0000             \n 1st Qu.:0.09735       1st Qu.:0.09735       1st Qu.:0.3727             \n Median :0.18361       Median :0.18361       Median :0.5184             \n Mean   :0.21225       Mean   :0.21267       Mean   :0.4949             \n 3rd Qu.:0.30455       3rd Qu.:0.30455       3rd Qu.:0.6242             \n Max.   :1.00000       Max.   :1.00000       Max.   :1.0000             \n mm_max_highest_60m_rainfall mm_max_highest_120m_rainfall mm_avg_mean_temp\n Min.   :0.0000              Min.   :0.0000               Min.   :0.0000  \n 1st Qu.:0.3021              1st Qu.:0.2752               1st Qu.:0.5572  \n Median :0.4250              Median :0.3941               Median :0.6546  \n Mean   :0.4167              Mean   :0.3960               Mean   :0.6518  \n 3rd Qu.:0.5536              3rd Qu.:0.5293               3rd Qu.:0.7633  \n Max.   :1.0000              Max.   :1.0000               Max.   :1.0000  \n mm_max_max_temp  mm_min_min_temp  mm_avg_mean_wind mm_max_max_wind \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.4769   1st Qu.:0.8911   1st Qu.:0.1709   1st Qu.:0.1946  \n Median :0.5692   Median :0.9113   Median :0.2746   Median :0.2749  \n Mean   :0.5558   Mean   :0.9050   Mean   :0.3076   Mean   :0.3059  \n 3rd Qu.:0.6462   3rd Qu.:0.9335   3rd Qu.:0.4027   3rd Qu.:0.3674  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\nwrite.csv(dengue_weather_wk_2014_tf, \"D:/MITB_SunYP/ISSS608/Data/dengue_climate_joined_by_week_2014_transformed.csv\")\n\n\npacman::p_load(tsibbledata, fable, feasts)\n\n\ndengue_weather_wk_2014_tf &lt;- dengue_weather_wk_2014_tf %&gt;%\n  mutate('Date' = make_date(year = Year) + weeks(WkNo))\n\n\ndengue_weather_tsreg &lt;- as_tsibble(dengue_weather_wk_2014_tf, index = Date)\n\n\nts_nf_m1 &lt;- dengue_weather_tsreg %&gt;%\n  model(TSLM(Cases ~ avg_daily_rainfall + \n                  tot_daily_rainfall +\n                  avg_mean_temp + \n                  max_max_temp +\n                  min_min_temp +\n                  avg_mean_wind +\n                  max_max_wind))\n\nreport(ts_nf_m1)\n\nSeries: Cases \nModel: TSLM \n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-404.86 -154.40  -47.88   71.27 1496.64 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        -1230.3043   751.9169  -1.636  0.10269    \navg_daily_rainfall   109.3640    97.6929   1.119  0.26371    \ntot_daily_rainfall   -13.5476    13.8809  -0.976  0.32974    \navg_mean_temp        113.4914    24.4987   4.633  5.1e-06 ***\nmax_max_temp         -61.3304    20.5544  -2.984  0.00305 ** \nmin_min_temp           3.9285     6.7536   0.582  0.56115    \navg_mean_wind         33.6337    10.3801   3.240  0.00131 ** \nmax_max_wind          -0.2650     0.9235  -0.287  0.77432    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 276.5 on 351 degrees of freedom\nMultiple R-squared: 0.08373,    Adjusted R-squared: 0.06546\nF-statistic: 4.582 on 7 and 351 DF, p-value: 6.4569e-05"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html",
    "title": "Choropleth Mapping with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#learning-outcome",
    "title": "Choropleth Mapping with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#getting-started",
    "title": "Choropleth Mapping with R",
    "section": "2. Getting Started",
    "text": "2. Getting Started\n\n2.1 Installing and loading the required libraries\nFirstly, let’s install and load the required packages:\n\ntidyverse: an opinionated collection of R packages designed for data import, data wrangling and data exploration\nsf: a standardized way to encode spatial vector data.\ntmap: makes it easier to plot thematic maps.\n\n\npacman::p_load(tidyverse, sf, tmap)\n\n\n\n2.2 Importing the data\nIn this exercise, two data sets will be used.\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\nLet’s start by importing the data.\n\n2.2.1 Importing Geospatial Data into R\nLet’s first import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz using st_read() function of sf package.\n\nmpsz &lt;- st_read(dsn = \"../../Data/hands-on_ex07/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\MITB_SunYP\\ISSS608\\Data\\hands-on_ex07\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n2.2.1 Importing Attribute Data into R\nWe then import respopagsex2011to2020.csv into R using read_csv() function of readr package.\n\npopdata &lt;- read_csv(\"../../Data/hands-on_ex07/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n2.3 Data Preparation\nIn this exercise, we will use the data in 2020 to plot the choropleth graphs, and we’ll use the following columns:\n\nPA: planning area\nSZ: subzone\nYOUNG: age group 0 to 4 until age group 20 to 24\nECONOMY ACTIVE: age group 25-29 until age group 60-64\nAGED: age group 65 and above\nTOTAL: all age group\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n2.3.1 Data wrangling\nLet’s first filter the data by year = 2020 and create the columns listed above.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG, \n              values_from = POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6]) +\n           rowSums(.[12])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11]) + \n           rowSums(.[13:15])) %&gt;%\n  mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`) / `ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, \n         `SZ`, \n         `YOUNG`,\n         `ECONOMY ACTIVE`, \n         `AGED`,\n         `TOTAL`, \n         `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n2.3.2 Joining the attribute data and geospatial data\nNext, we join the attribute data with the geospatial data.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n            .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n\n2.3.3 Saving the rds data\nWe have now prepared the data, and we can save it for future use.\n\nwrite_rds(mpsz_pop2020, \"../../Data/hands-on_ex07/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Choropleth Mapping with R",
    "section": "3. Choropleth Mapping Geospatial Data Using tmap",
    "text": "3. Choropleth Mapping Geospatial Data Using tmap\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\nWe’ll explore both methods in the next sections.\n\n3.1 Plotting a choropleth map quickly by using qtm()\nLet’s draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nIn the map above, we show the subzone boundaries and the color indicates the ratio of young-old dependency. There is one subzone in the east having significantly higher dependency ratio.\n\n\n3.2 Creating a choropleth map by using tmap’s elements\nNext, we’ll customize the choropleth map using tmap elements.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n3.2.1 Drawing a base map\nLet’s see how the map above is plotted step-by-step.\nFirst, we create a base map.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n3.2.2 Drawing a choropleth map using tm_polygons()\nFill the color by indicating the fill variable.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n3.2.3 Drawing a choropleth map using tm_fill() and tm_border()\nWe remove the border of the polygons by change tm_polygons() to tm_fill().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nWe then add the boundaries back with customization.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n3.2.4 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nLet’s first see how built-in classification methods look like.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nCompare to equal data classification method.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that we can’t really see the differences in dependency ratio when the values are classified with a equal distance. Therefore, the quantile data classification method is better in this case.\nIn addition to the standard data classification methods provided, we can also customize our own classification methods.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n3.2.5 Colour Scheme\nLet’s now change to another color scheme.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can also reverse the color shading.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n3.2.6 Map Layouts\nLedend and title can be added on the maps using the code below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can also customize the map style using the code below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\nWe can also draw other map furniture such as compass, scale bar and grid lines.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n3.3 Drawing Small Multiple Choropleth Maps\nWe can also draw mutiple choropleth maps for different variables.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nWe can also customize each choropleth map using the code below.\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\", \"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\nIn addition, we can draw different choropleth maps by different categories.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by = \"REGION_N\", \n            free.coords = TRUE, \n            drop.shapes = FALSE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\nOr we can arrange them in the way we want.\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) + \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020) + \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n3.4 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, we can also use selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N == \"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend\n\n\n\n\n\nThis comes to the end of this hands-on exercise. I have learned to plot choropleth maps using geospatial and attribute data in R. Hope you enjoyed it, too!\nSee you in the next hands-on exercise 🥰"
  }
]